{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17bb2871d88>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),cmap='Blues')\n",
    "# Dark Blue part are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17bb1d17e48>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.notnull(),xticklabels=False,\n",
    "            yticklabels=False,cmap='viridis')\n",
    "# yellow part are not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1453\n",
       "MiscFeature     1406\n",
       "Alley           1369\n",
       "Fence           1179\n",
       "FireplaceQu      690\n",
       "LotFrontage      259\n",
       "GarageCond        81\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1460 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1460 non-null   object \n",
      " 30  BsmtCond       1460 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(42)\n",
      "memory usage: 912.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireplaceQu     690\n",
       "GarageYrBlt      81\n",
       "GarageType       81\n",
       "BsmtExposure     38\n",
       "BsmtFinType2     38\n",
       "BsmtFinType1     37\n",
       "MasVnrType        8\n",
       "MasVnrArea        8\n",
       "Electrical        1\n",
       "LotArea           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireplaceQu     690\n",
       "GarageType       81\n",
       "BsmtExposure     38\n",
       "BsmtFinType2     38\n",
       "BsmtFinType1     37\n",
       "MasVnrType        8\n",
       "MasVnrArea        8\n",
       "Electrical        1\n",
       "LotFrontage       0\n",
       "ExterQual         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mean())\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireplaceQu     690\n",
       "GarageType       81\n",
       "BsmtExposure     38\n",
       "BsmtFinType2     38\n",
       "BsmtFinType1     37\n",
       "Electrical        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical']=df['Electrical'].fillna(df['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireplaceQu    690\n",
       "GarageType      81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType1']=df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17bb4640288>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17bb4640088>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_hot_encoding(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i+=1\n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_hot_encoding(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('clean_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 75)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=on_hot_encoding(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>Fa</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Po</th>\n",
       "      <th>TA</th>\n",
       "      <th>Fa</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Po</th>\n",
       "      <th>TA</th>\n",
       "      <th>P</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows Ã— 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0            65.0     8450            7            5       2003          2003   \n",
       "1            80.0     9600            6            8       1976          1976   \n",
       "2            68.0    11250            7            5       2001          2002   \n",
       "3            60.0     9550            7            5       1915          1970   \n",
       "4            84.0    14260            8            5       2000          2000   \n",
       "...           ...      ...          ...          ...        ...           ...   \n",
       "1454         21.0     1936            4            7       1970          1970   \n",
       "1455         21.0     1894            4            5       1970          1970   \n",
       "1456        160.0    20000            5            7       1960          1996   \n",
       "1457         62.0    10441            5            5       1992          1992   \n",
       "1458         74.0     9627            7            5       1993          1994   \n",
       "\n",
       "      MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  Fa  Gd  Po  TA  Fa  \\\n",
       "0          196.0       706.0         0.0      150.0  ...   0   0   0   1   0   \n",
       "1            0.0       978.0         0.0      284.0  ...   0   0   0   1   0   \n",
       "2          162.0       486.0         0.0      434.0  ...   0   0   0   1   0   \n",
       "3            0.0       216.0         0.0      540.0  ...   0   0   0   1   0   \n",
       "4          350.0       655.0         0.0      490.0  ...   0   0   0   1   0   \n",
       "...          ...         ...         ...        ...  ...  ..  ..  ..  ..  ..   \n",
       "1454         0.0         0.0         0.0      546.0  ...   0   0   0   1   0   \n",
       "1455         0.0       252.0         0.0      294.0  ...   0   0   0   1   0   \n",
       "1456         0.0      1224.0         0.0        0.0  ...   0   0   0   1   0   \n",
       "1457         0.0       337.0         0.0      575.0  ...   0   0   0   1   0   \n",
       "1458        94.0       758.0         0.0      238.0  ...   0   0   0   1   0   \n",
       "\n",
       "      Gd  Po  TA  P  Y  \n",
       "0      0   0   1  0  1  \n",
       "1      0   0   1  0  1  \n",
       "2      0   0   1  0  1  \n",
       "3      0   0   1  0  1  \n",
       "4      0   0   1  0  1  \n",
       "...   ..  ..  .. .. ..  \n",
       "1454   0   0   1  0  1  \n",
       "1455   0   0   1  0  1  \n",
       "1456   0   0   1  0  1  \n",
       "1457   0   0   1  0  1  \n",
       "1458   0   0   1  0  1  \n",
       "\n",
       "[2919 rows x 236 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0            65.0     8450            7            5       2003          2003   \n",
       "1            80.0     9600            6            8       1976          1976   \n",
       "2            68.0    11250            7            5       2001          2002   \n",
       "3            60.0     9550            7            5       1915          1970   \n",
       "4            84.0    14260            8            5       2000          2000   \n",
       "...           ...      ...          ...          ...        ...           ...   \n",
       "1454         21.0     1936            4            7       1970          1970   \n",
       "1455         21.0     1894            4            5       1970          1970   \n",
       "1456        160.0    20000            5            7       1960          1996   \n",
       "1457         62.0    10441            5            5       1992          1992   \n",
       "1458         74.0     9627            7            5       1993          1994   \n",
       "\n",
       "      MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  Min1  Min2  Typ  \\\n",
       "0          196.0       706.0         0.0      150.0  ...     0     0    1   \n",
       "1            0.0       978.0         0.0      284.0  ...     0     0    1   \n",
       "2          162.0       486.0         0.0      434.0  ...     0     0    1   \n",
       "3            0.0       216.0         0.0      540.0  ...     0     0    1   \n",
       "4          350.0       655.0         0.0      490.0  ...     0     0    1   \n",
       "...          ...         ...         ...        ...  ...   ...   ...  ...   \n",
       "1454         0.0         0.0         0.0      546.0  ...     0     0    1   \n",
       "1455         0.0       252.0         0.0      294.0  ...     0     0    1   \n",
       "1456         0.0      1224.0         0.0        0.0  ...     0     0    1   \n",
       "1457         0.0       337.0         0.0      575.0  ...     0     0    1   \n",
       "1458        94.0       758.0         0.0      238.0  ...     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    1  0  \n",
       "1          1        0        0        0       0    1  0  \n",
       "2          1        0        0        0       0    1  0  \n",
       "3          0        0        0        0       1    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[2919 rows x 176 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=final_df.iloc[:1460,:]\n",
    "df_test=final_df.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rissu\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='finalmodel.pkl'\n",
    "pickle.dump(classifier,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor()\n",
    "base_score=[0.25,0.5,0.75,1]\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_cv=RandomizedSearchCV(estimator=regressor,\n",
    "                         param_distributions=hyperparameter_grid,\n",
    "                        cv=5,n_iter=50,\n",
    "                            scoring='neg_mean_absolute_error',n_jobs=4,\n",
    "                            verbose=5,\n",
    "                            return_train_score=True,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_...\n",
       "                   iid='deprecated', n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 900,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'booster': 'gbtree',\n",
       " 'base_score': 0.25}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "             min_child_weight=1, missing=None, monotone_constraints=None,\n",
    "             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306795</td>\n",
       "      <td>0.234196</td>\n",
       "      <td>-0.052820</td>\n",
       "      <td>0.117598</td>\n",
       "      <td>0.082746</td>\n",
       "      <td>0.179283</td>\n",
       "      <td>0.215828</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.122156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.174217</td>\n",
       "      <td>0.041244</td>\n",
       "      <td>0.076699</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>-0.243313</td>\n",
       "      <td>0.127648</td>\n",
       "      <td>-0.012554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.306795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>0.014228</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.103960</td>\n",
       "      <td>0.214103</td>\n",
       "      <td>0.111170</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.010409</td>\n",
       "      <td>-0.036048</td>\n",
       "      <td>0.090940</td>\n",
       "      <td>-0.000956</td>\n",
       "      <td>0.037552</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>-0.126094</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.012568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.234196</td>\n",
       "      <td>0.105806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091932</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.550684</td>\n",
       "      <td>0.410238</td>\n",
       "      <td>0.239666</td>\n",
       "      <td>-0.059119</td>\n",
       "      <td>0.308159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089623</td>\n",
       "      <td>-0.126065</td>\n",
       "      <td>0.174427</td>\n",
       "      <td>0.242807</td>\n",
       "      <td>-0.025734</td>\n",
       "      <td>0.198299</td>\n",
       "      <td>-0.100601</td>\n",
       "      <td>-0.337227</td>\n",
       "      <td>0.218673</td>\n",
       "      <td>-0.076757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>-0.052820</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>-0.091932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.375983</td>\n",
       "      <td>0.073741</td>\n",
       "      <td>-0.127788</td>\n",
       "      <td>-0.046231</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>-0.136841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003569</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>0.081743</td>\n",
       "      <td>-0.121648</td>\n",
       "      <td>-0.015926</td>\n",
       "      <td>-0.063721</td>\n",
       "      <td>-0.032867</td>\n",
       "      <td>0.183224</td>\n",
       "      <td>-0.090723</td>\n",
       "      <td>0.068313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.117598</td>\n",
       "      <td>0.014228</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>-0.375983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592855</td>\n",
       "      <td>0.314745</td>\n",
       "      <td>0.249503</td>\n",
       "      <td>-0.049107</td>\n",
       "      <td>0.149040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082821</td>\n",
       "      <td>-0.128924</td>\n",
       "      <td>0.174034</td>\n",
       "      <td>0.375284</td>\n",
       "      <td>-0.043454</td>\n",
       "      <td>0.201547</td>\n",
       "      <td>-0.056346</td>\n",
       "      <td>-0.487130</td>\n",
       "      <td>0.314221</td>\n",
       "      <td>-0.180702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BuiltIn</th>\n",
       "      <td>0.076699</td>\n",
       "      <td>0.037552</td>\n",
       "      <td>0.198299</td>\n",
       "      <td>-0.063721</td>\n",
       "      <td>0.201547</td>\n",
       "      <td>0.184043</td>\n",
       "      <td>0.116666</td>\n",
       "      <td>-0.069965</td>\n",
       "      <td>-0.062664</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037302</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>-0.346175</td>\n",
       "      <td>-0.029081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019946</td>\n",
       "      <td>-0.152097</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>-0.036682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CarPort</th>\n",
       "      <td>0.021304</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>-0.100601</td>\n",
       "      <td>-0.032867</td>\n",
       "      <td>-0.056346</td>\n",
       "      <td>-0.065208</td>\n",
       "      <td>-0.036367</td>\n",
       "      <td>-0.014908</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>-0.070470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049102</td>\n",
       "      <td>-0.012161</td>\n",
       "      <td>-0.047932</td>\n",
       "      <td>-0.107651</td>\n",
       "      <td>-0.009043</td>\n",
       "      <td>-0.019946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047298</td>\n",
       "      <td>-0.050216</td>\n",
       "      <td>-0.011407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detchd</th>\n",
       "      <td>-0.243313</td>\n",
       "      <td>-0.126094</td>\n",
       "      <td>-0.337227</td>\n",
       "      <td>0.183224</td>\n",
       "      <td>-0.487130</td>\n",
       "      <td>-0.310921</td>\n",
       "      <td>-0.184065</td>\n",
       "      <td>-0.212286</td>\n",
       "      <td>-0.027893</td>\n",
       "      <td>-0.075678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029957</td>\n",
       "      <td>0.030742</td>\n",
       "      <td>-0.076754</td>\n",
       "      <td>-0.820894</td>\n",
       "      <td>-0.068961</td>\n",
       "      <td>-0.152097</td>\n",
       "      <td>-0.047298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.317882</td>\n",
       "      <td>0.109912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFn</th>\n",
       "      <td>0.127648</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.218673</td>\n",
       "      <td>-0.090723</td>\n",
       "      <td>0.314221</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.057695</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041507</td>\n",
       "      <td>-0.038344</td>\n",
       "      <td>0.089153</td>\n",
       "      <td>0.304769</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>-0.050216</td>\n",
       "      <td>-0.317882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>-0.012554</td>\n",
       "      <td>0.012568</td>\n",
       "      <td>-0.076757</td>\n",
       "      <td>0.068313</td>\n",
       "      <td>-0.180702</td>\n",
       "      <td>-0.135676</td>\n",
       "      <td>-0.073864</td>\n",
       "      <td>-0.079791</td>\n",
       "      <td>-0.041809</td>\n",
       "      <td>0.024459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021333</td>\n",
       "      <td>-0.022365</td>\n",
       "      <td>0.039276</td>\n",
       "      <td>-0.076403</td>\n",
       "      <td>-0.016632</td>\n",
       "      <td>-0.036682</td>\n",
       "      <td>-0.011407</td>\n",
       "      <td>0.109912</td>\n",
       "      <td>-0.060401</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "LotFrontage     1.000000  0.306795     0.234196    -0.052820   0.117598   \n",
       "LotArea         0.306795  1.000000     0.105806    -0.005636   0.014228   \n",
       "OverallQual     0.234196  0.105806     1.000000    -0.091932   0.572323   \n",
       "OverallCond    -0.052820 -0.005636    -0.091932     1.000000  -0.375983   \n",
       "YearBuilt       0.117598  0.014228     0.572323    -0.375983   1.000000   \n",
       "...                  ...       ...          ...          ...        ...   \n",
       "BuiltIn         0.076699  0.037552     0.198299    -0.063721   0.201547   \n",
       "CarPort         0.021304  0.009136    -0.100601    -0.032867  -0.056346   \n",
       "Detchd         -0.243313 -0.126094    -0.337227     0.183224  -0.487130   \n",
       "RFn             0.127648  0.014502     0.218673    -0.090723   0.314221   \n",
       "P              -0.012554  0.012568    -0.076757     0.068313  -0.180702   \n",
       "\n",
       "             YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "LotFrontage      0.082746    0.179283    0.215828    0.043340   0.122156  ...   \n",
       "LotArea          0.013788    0.103960    0.214103    0.111170  -0.002618  ...   \n",
       "OverallQual      0.550684    0.410238    0.239666   -0.059119   0.308159  ...   \n",
       "OverallCond      0.073741   -0.127788   -0.046231    0.040229  -0.136841  ...   \n",
       "YearBuilt        0.592855    0.314745    0.249503   -0.049107   0.149040  ...   \n",
       "...                   ...         ...         ...         ...        ...  ...   \n",
       "BuiltIn          0.184043    0.116666   -0.069965   -0.062664   0.063465  ...   \n",
       "CarPort         -0.065208   -0.036367   -0.014908    0.064902  -0.070470  ...   \n",
       "Detchd          -0.310921   -0.184065   -0.212286   -0.027893  -0.075678  ...   \n",
       "RFn              0.197788    0.116974    0.057695    0.007591   0.105031  ...   \n",
       "P               -0.135676   -0.073864   -0.079791   -0.041809   0.024459  ...   \n",
       "\n",
       "                 Min1      Min2       Typ    Attchd   Basment   BuiltIn  \\\n",
       "LotFrontage -0.019681  0.003837  0.022926  0.174217  0.041244  0.076699   \n",
       "LotArea      0.029287  0.010409 -0.036048  0.090940 -0.000956  0.037552   \n",
       "OverallQual -0.089623 -0.126065  0.174427  0.242807 -0.025734  0.198299   \n",
       "OverallCond -0.003569 -0.006376  0.081743 -0.121648 -0.015926 -0.063721   \n",
       "YearBuilt   -0.082821 -0.128924  0.174034  0.375284 -0.043454  0.201547   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "BuiltIn     -0.037302  0.018141  0.023100 -0.346175 -0.029081  1.000000   \n",
       "CarPort      0.049102 -0.012161 -0.047932 -0.107651 -0.009043 -0.019946   \n",
       "Detchd       0.029957  0.030742 -0.076754 -0.820894 -0.068961 -0.152097   \n",
       "RFn         -0.041507 -0.038344  0.089153  0.304769  0.006775 -0.009114   \n",
       "P           -0.021333 -0.022365  0.039276 -0.076403 -0.016632 -0.036682   \n",
       "\n",
       "              CarPort    Detchd       RFn         P  \n",
       "LotFrontage  0.021304 -0.243313  0.127648 -0.012554  \n",
       "LotArea      0.009136 -0.126094  0.014502  0.012568  \n",
       "OverallQual -0.100601 -0.337227  0.218673 -0.076757  \n",
       "OverallCond -0.032867  0.183224 -0.090723  0.068313  \n",
       "YearBuilt   -0.056346 -0.487130  0.314221 -0.180702  \n",
       "...               ...       ...       ...       ...  \n",
       "BuiltIn     -0.019946 -0.152097 -0.009114 -0.036682  \n",
       "CarPort      1.000000 -0.047298 -0.050216 -0.011407  \n",
       "Detchd      -0.047298  1.000000 -0.317882  0.109912  \n",
       "RFn         -0.050216 -0.317882  1.000000 -0.060401  \n",
       "P           -0.011407  0.109912 -0.060401  1.000000  \n",
       "\n",
       "[176 rows x 176 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rissu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=175, units=50, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=50,init='uniform',activation='relu',\n",
    "                    input_dim=175))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rissu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=25,init='uniform',\n",
    "                    activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rissu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=50,init='uniform',\n",
    "                    activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rissu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=1,init='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "classifier.compile(loss='mean_squared_error',\n",
    "                  optimizer='Adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1168/1168 [==============================] - 1s 1ms/step - loss: 38819414314.0822 - val_loss: 39918500920.1096\n",
      "Epoch 2/1000\n",
      "1168/1168 [==============================] - 0s 218us/step - loss: 38819351040.0000 - val_loss: 39918436127.5616\n",
      "Epoch 3/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38819286335.1233 - val_loss: 39918368922.3014\n",
      "Epoch 4/1000\n",
      "1168/1168 [==============================] - 0s 220us/step - loss: 38819226739.7260 - val_loss: 39918311943.0137\n",
      "Epoch 5/1000\n",
      "1168/1168 [==============================] - 0s 221us/step - loss: 38819167358.2466 - val_loss: 39918249871.7808\n",
      "Epoch 6/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38819102919.8904 - val_loss: 39918186411.8356\n",
      "Epoch 7/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38819045162.0822 - val_loss: 39918128941.5890\n",
      "Epoch 8/1000\n",
      "1168/1168 [==============================] - 0s 218us/step - loss: 38818983793.9726 - val_loss: 39918064976.6575\n",
      "Epoch 9/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38818921664.8767 - val_loss: 39918005163.8356\n",
      "Epoch 10/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38818863219.7260 - val_loss: 39917944298.9589\n",
      "Epoch 11/1000\n",
      "1168/1168 [==============================] - 0s 258us/step - loss: 38818799749.2603 - val_loss: 39917878243.9452\n",
      "Epoch 12/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38818738572.2740 - val_loss: 39917817870.0274\n",
      "Epoch 13/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38818675357.8082 - val_loss: 39917753905.0959\n",
      "Epoch 14/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38818612104.7671 - val_loss: 39917689743.7808\n",
      "Epoch 15/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38818545941.0411 - val_loss: 39917624137.6438\n",
      "Epoch 16/1000\n",
      "1168/1168 [==============================] - 0s 215us/step - loss: 38818486170.3014 - val_loss: 39917566316.7123\n",
      "Epoch 17/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38818428145.9726 - val_loss: 39917506391.6712\n",
      "Epoch 18/1000\n",
      "1168/1168 [==============================] - 0s 249us/step - loss: 38818367365.2603 - val_loss: 39917440519.0137\n",
      "Epoch 19/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38818304448.8767 - val_loss: 39917378531.9452\n",
      "Epoch 20/1000\n",
      "1168/1168 [==============================] - 0s 256us/step - loss: 38818241486.9041 - val_loss: 39917316039.8904\n",
      "Epoch 21/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38818177969.0959 - val_loss: 39917252355.5069\n",
      "Epoch 22/1000\n",
      "1168/1168 [==============================] - 0s 220us/step - loss: 38818118470.1370 - val_loss: 39917195235.9452\n",
      "Epoch 23/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38818056321.7534 - val_loss: 39917127680.0000\n",
      "Epoch 24/1000\n",
      "1168/1168 [==============================] - 0s 251us/step - loss: 38817991946.5205 - val_loss: 39917062606.9041\n",
      "Epoch 25/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38817928409.4247 - val_loss: 39917002162.8493\n",
      "Epoch 26/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38817869911.6712 - val_loss: 39916944341.9178\n",
      "Epoch 27/1000\n",
      "1168/1168 [==============================] - 0s 215us/step - loss: 38817808110.4658 - val_loss: 39916876561.5342\n",
      "Epoch 28/1000\n",
      "1168/1168 [==============================] - 0s 211us/step - loss: 38817744156.0548 - val_loss: 39916814560.4384\n",
      "Epoch 29/1000\n",
      "1168/1168 [==============================] - 0s 213us/step - loss: 38817681183.5616 - val_loss: 39916751240.7671\n",
      "Epoch 30/1000\n",
      "1168/1168 [==============================] - 0s 278us/step - loss: 38817615766.7945 - val_loss: 39916683825.0959\n",
      "Epoch 31/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38817553081.8630 - val_loss: 39916621753.8630\n",
      "Epoch 32/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38817490510.9041 - val_loss: 39916557662.6849\n",
      "Epoch 33/1000\n",
      "1168/1168 [==============================] - 0s 220us/step - loss: 38817431513.4247 - val_loss: 39916500543.1233\n",
      "Epoch 34/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38817370269.8082 - val_loss: 39916436367.7808\n",
      "Epoch 35/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38817306133.0411 - val_loss: 39916375011.9452\n",
      "Epoch 36/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38817247708.9315 - val_loss: 39916317681.9726\n",
      "Epoch 37/1000\n",
      "1168/1168 [==============================] - 0s 265us/step - loss: 38817187131.6164 - val_loss: 39916250476.7123\n",
      "Epoch 38/1000\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 38817126161.5342 - val_loss: 39916193637.6986\n",
      "Epoch 39/1000\n",
      "1168/1168 [==============================] - 0s 275us/step - loss: 38817067425.3151 - val_loss: 39916134694.5753\n",
      "Epoch 40/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38817006988.2740 - val_loss: 39916071921.9726\n",
      "Epoch 41/1000\n",
      "1168/1168 [==============================] - 0s 269us/step - loss: 38816944133.2603 - val_loss: 39916006596.3836\n",
      "Epoch 42/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38816878849.7534 - val_loss: 39915942926.0274\n",
      "Epoch 43/1000\n",
      "1168/1168 [==============================] - 0s 249us/step - loss: 38816819196.4931 - val_loss: 39915885876.6027\n",
      "Epoch 44/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38816762501.2603 - val_loss: 39915824590.9041\n",
      "Epoch 45/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38816701075.2877 - val_loss: 39915760008.7671\n",
      "Epoch 46/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38816637457.5342 - val_loss: 39915698442.5205\n",
      "Epoch 47/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38816577227.3973 - val_loss: 39915639274.9589\n",
      "Epoch 48/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38816519041.7534 - val_loss: 39915578971.1781\n",
      "Epoch 49/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38816457080.9863 - val_loss: 39915516142.4658\n",
      "Epoch 50/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38816395470.9041 - val_loss: 39915453159.4521\n",
      "Epoch 51/1000\n",
      "1168/1168 [==============================] - 0s 218us/step - loss: 38816333764.3836 - val_loss: 39915392154.3014\n",
      "Epoch 52/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38816269080.5479 - val_loss: 39915327361.7534\n",
      "Epoch 53/1000\n",
      "1168/1168 [==============================] - 0s 217us/step - loss: 38816206686.6849 - val_loss: 39915262428.9315\n",
      "Epoch 54/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38816143868.4931 - val_loss: 39915201339.6164\n",
      "Epoch 55/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38816083638.3562 - val_loss: 39915141091.9452\n",
      "Epoch 56/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38816023110.1370 - val_loss: 39915081461.4795\n",
      "Epoch 57/1000\n",
      "1168/1168 [==============================] - 0s 218us/step - loss: 38815966421.9178 - val_loss: 39915020302.0274\n",
      "Epoch 58/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38815904406.7945 - val_loss: 39914959717.6986\n",
      "Epoch 59/1000\n",
      "1168/1168 [==============================] - 0s 214us/step - loss: 38815841760.4384 - val_loss: 39914894504.3288\n",
      "Epoch 60/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38815777821.8082 - val_loss: 39914826387.2877\n",
      "Epoch 61/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38815713521.9726 - val_loss: 39914768341.9178\n",
      "Epoch 62/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38815653309.3699 - val_loss: 39914705863.8904\n",
      "Epoch 63/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38815589077.9178 - val_loss: 39914639626.5205\n",
      "Epoch 64/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38815524828.9315 - val_loss: 39914574553.4247\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 219us/step - loss: 38815457788.4931 - val_loss: 39914507839.1233\n",
      "Epoch 66/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38815396779.8356 - val_loss: 39914449457.0959\n",
      "Epoch 67/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38815338334.6849 - val_loss: 39914386123.3973\n",
      "Epoch 68/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38815277341.8082 - val_loss: 39914324697.4247\n",
      "Epoch 69/1000\n",
      "1168/1168 [==============================] - 0s 218us/step - loss: 38815216180.6027 - val_loss: 39914263748.3836\n",
      "Epoch 70/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38815154979.0685 - val_loss: 39914199727.3425\n",
      "Epoch 71/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38815095283.7260 - val_loss: 39914144080.6575\n",
      "Epoch 72/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38815038460.4931 - val_loss: 39914085137.5342\n",
      "Epoch 73/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38814975751.0137 - val_loss: 39914019194.7397\n",
      "Epoch 74/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38814911040.8767 - val_loss: 39913952985.4247\n",
      "Epoch 75/1000\n",
      "1168/1168 [==============================] - 0s 215us/step - loss: 38814848932.8219 - val_loss: 39913892751.7808\n",
      "Epoch 76/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38814788173.1507 - val_loss: 39913831115.3973\n",
      "Epoch 77/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38814722062.0274 - val_loss: 39913762142.6849\n",
      "Epoch 78/1000\n",
      "1168/1168 [==============================] - 0s 215us/step - loss: 38814658400.4384 - val_loss: 39913702568.3288\n",
      "Epoch 79/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38814596611.5069 - val_loss: 39913637677.5890\n",
      "Epoch 80/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38814533979.1781 - val_loss: 39913573011.2877\n",
      "Epoch 81/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38814469551.3425 - val_loss: 39913511795.7260\n",
      "Epoch 82/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38814409384.3288 - val_loss: 39913451590.1370\n",
      "Epoch 83/1000\n",
      "1168/1168 [==============================] - 0s 211us/step - loss: 38814351046.1370 - val_loss: 39913391202.1918\n",
      "Epoch 84/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38814289432.5479 - val_loss: 39913329215.1233\n",
      "Epoch 85/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38814231559.0137 - val_loss: 39913273217.7534\n",
      "Epoch 86/1000\n",
      "1168/1168 [==============================] - 0s 221us/step - loss: 38814170851.9452 - val_loss: 39913209687.6712\n",
      "Epoch 87/1000\n",
      "1168/1168 [==============================] - 0s 300us/step - loss: 38814106760.7671 - val_loss: 39913144614.5753\n",
      "Epoch 88/1000\n",
      "1168/1168 [==============================] - 0s 220us/step - loss: 38814043528.7671 - val_loss: 39913081856.0000\n",
      "Epoch 89/1000\n",
      "1168/1168 [==============================] - 0s 213us/step - loss: 38813982109.8082 - val_loss: 39913019363.9452\n",
      "Epoch 90/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38813917881.8630 - val_loss: 39912953968.2192\n",
      "Epoch 91/1000\n",
      "1168/1168 [==============================] - 0s 328us/step - loss: 38813853327.7808 - val_loss: 39912889666.6301\n",
      "Epoch 92/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38813789573.2603 - val_loss: 39912821970.4110\n",
      "Epoch 93/1000\n",
      "1168/1168 [==============================] - 0s 217us/step - loss: 38813726025.6438 - val_loss: 39912760614.5753\n",
      "Epoch 94/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38813662467.5069 - val_loss: 39912696579.5069\n",
      "Epoch 95/1000\n",
      "1168/1168 [==============================] - 0s 302us/step - loss: 38813598193.9726 - val_loss: 39912629009.5342\n",
      "Epoch 96/1000\n",
      "1168/1168 [==============================] - 0s 216us/step - loss: 38813536329.6438 - val_loss: 39912570066.4110\n",
      "Epoch 97/1000\n",
      "1168/1168 [==============================] - 0s 213us/step - loss: 38813472561.0959 - val_loss: 39912502720.8767\n",
      "Epoch 98/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38813408932.8219 - val_loss: 39912441084.4931\n",
      "Epoch 99/1000\n",
      "1168/1168 [==============================] - 0s 317us/step - loss: 38813345802.5205 - val_loss: 39912376642.6301\n",
      "Epoch 100/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38813283855.7808 - val_loss: 39912316114.4110\n",
      "Epoch 101/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38813226366.2466 - val_loss: 39912256750.4658\n",
      "Epoch 102/1000\n",
      "1168/1168 [==============================] - 0s 274us/step - loss: 38813165347.0685 - val_loss: 39912194819.5069\n",
      "Epoch 103/1000\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 38813101866.0822 - val_loss: 39912130798.4658\n",
      "Epoch 104/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38813043245.5890 - val_loss: 39912073187.9452\n",
      "Epoch 105/1000\n",
      "1168/1168 [==============================] - 0s 218us/step - loss: 38812985652.6027 - val_loss: 39912012954.3014\n",
      "Epoch 106/1000\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 38812923619.9452 - val_loss: 39911949213.8082\n",
      "Epoch 107/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38812863165.3699 - val_loss: 39911888825.8630\n",
      "Epoch 108/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38812801167.7808 - val_loss: 39911826277.6986\n",
      "Epoch 109/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38812737528.9863 - val_loss: 39911761976.1096\n",
      "Epoch 110/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38812673607.8904 - val_loss: 39911698432.0000\n",
      "Epoch 111/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38812611762.8493 - val_loss: 39911633400.9863\n",
      "Epoch 112/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38812548897.3151 - val_loss: 39911572844.7123\n",
      "Epoch 113/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38812485884.4931 - val_loss: 39911508374.7945\n",
      "Epoch 114/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38812422450.8493 - val_loss: 39911442726.5753\n",
      "Epoch 115/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38812359055.7808 - val_loss: 39911379252.6027\n",
      "Epoch 116/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38812295511.6712 - val_loss: 39911317966.9041\n",
      "Epoch 117/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38812232216.5479 - val_loss: 39911250831.7808\n",
      "Epoch 118/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38812171437.5890 - val_loss: 39911192870.5753\n",
      "Epoch 119/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38812110567.4521 - val_loss: 39911128919.6712\n",
      "Epoch 120/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38812047388.0548 - val_loss: 39911063944.7671\n",
      "Epoch 121/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38811982781.3699 - val_loss: 39911003178.0822\n",
      "Epoch 122/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38811923831.2329 - val_loss: 39910942649.8630\n",
      "Epoch 123/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38811865912.1096 - val_loss: 39910884899.0685\n",
      "Epoch 124/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38811805005.1507 - val_loss: 39910821088.4384\n",
      "Epoch 125/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38811743000.5479 - val_loss: 39910759101.3699\n",
      "Epoch 126/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38811683647.1233 - val_loss: 39910702683.1781\n",
      "Epoch 127/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38811626359.2329 - val_loss: 39910641874.4110\n",
      "Epoch 128/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38811567096.9863 - val_loss: 39910582524.4931\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 234us/step - loss: 38811504566.3562 - val_loss: 39910520172.7123\n",
      "Epoch 130/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38811442880.8767 - val_loss: 39910453374.2466\n",
      "Epoch 131/1000\n",
      "1168/1168 [==============================] - 0s 221us/step - loss: 38811380480.0000 - val_loss: 39910395904.0000\n",
      "Epoch 132/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38811322995.7260 - val_loss: 39910338433.7534\n",
      "Epoch 133/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38811262944.4384 - val_loss: 39910273781.4795\n",
      "Epoch 134/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38811198698.9589 - val_loss: 39910208750.4658\n",
      "Epoch 135/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38811135260.0548 - val_loss: 39910144939.8356\n",
      "Epoch 136/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38811074672.2192 - val_loss: 39910084551.8904\n",
      "Epoch 137/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38811014056.3288 - val_loss: 39910023210.0822\n",
      "Epoch 138/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38810952116.6027 - val_loss: 39909962625.7534\n",
      "Epoch 139/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38810889398.3562 - val_loss: 39909898815.1233\n",
      "Epoch 140/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38810829611.8356 - val_loss: 39909837459.2877\n",
      "Epoch 141/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38810768033.3151 - val_loss: 39909773368.1096\n",
      "Epoch 142/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38810705457.0959 - val_loss: 39909711872.0000\n",
      "Epoch 143/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38810642712.5479 - val_loss: 39909648257.7534\n",
      "Epoch 144/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38810580753.5342 - val_loss: 39909587098.3014\n",
      "Epoch 145/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38810517442.6301 - val_loss: 39909522375.8904\n",
      "Epoch 146/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38810457137.0959 - val_loss: 39909461511.0137\n",
      "Epoch 147/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38810392958.2466 - val_loss: 39909394375.8904\n",
      "Epoch 148/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38810328786.4110 - val_loss: 39909329302.7945\n",
      "Epoch 149/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38810264623.3425 - val_loss: 39909267652.3836\n",
      "Epoch 150/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38810202006.7945 - val_loss: 39909204178.4110\n",
      "Epoch 151/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38810138452.1644 - val_loss: 39909138936.9863\n",
      "Epoch 152/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38810076952.5479 - val_loss: 39909079292.4931\n",
      "Epoch 153/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38810019815.4521 - val_loss: 39909022313.2055\n",
      "Epoch 154/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38809958389.4795 - val_loss: 39908955458.6301\n",
      "Epoch 155/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38809893589.9178 - val_loss: 39908891507.7260\n",
      "Epoch 156/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38809833391.3425 - val_loss: 39908835426.1918\n",
      "Epoch 157/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38809775517.8082 - val_loss: 39908773916.0548\n",
      "Epoch 158/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38809712113.9726 - val_loss: 39908706079.5616\n",
      "Epoch 159/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38809643881.2055 - val_loss: 39908637541.6986\n",
      "Epoch 160/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38809577401.8630 - val_loss: 39908573029.6986\n",
      "Epoch 161/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38809512826.7397 - val_loss: 39908509415.4521\n",
      "Epoch 162/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38809454279.8904 - val_loss: 39908452366.0274\n",
      "Epoch 163/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38809394986.0822 - val_loss: 39908390308.8219\n",
      "Epoch 164/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38809334093.1507 - val_loss: 39908327395.9452\n",
      "Epoch 165/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38809270482.4110 - val_loss: 39908261453.1507\n",
      "Epoch 166/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38809205882.7397 - val_loss: 39908197572.3836\n",
      "Epoch 167/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38809142101.9178 - val_loss: 39908132765.8082\n",
      "Epoch 168/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38809078456.1096 - val_loss: 39908071550.2466\n",
      "Epoch 169/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38809016328.7671 - val_loss: 39908004962.1918\n",
      "Epoch 170/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38808955076.3836 - val_loss: 39907947281.5342\n",
      "Epoch 171/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38808895922.8493 - val_loss: 39907886416.6575\n",
      "Epoch 172/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38808834889.6438 - val_loss: 39907822886.5753\n",
      "Epoch 173/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38808771999.5616 - val_loss: 39907757743.3425\n",
      "Epoch 174/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38808708201.2055 - val_loss: 39907697285.2603\n",
      "Epoch 175/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38808641944.5479 - val_loss: 39907627821.5890\n",
      "Epoch 176/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38808575095.2329 - val_loss: 39907559985.0959\n",
      "Epoch 177/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38808513388.7123 - val_loss: 39907502374.5753\n",
      "Epoch 178/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38808452197.6986 - val_loss: 39907439195.1781\n",
      "Epoch 179/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38808390694.5753 - val_loss: 39907377348.3836\n",
      "Epoch 180/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38808328402.4110 - val_loss: 39907310199.2329\n",
      "Epoch 181/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38808263781.6986 - val_loss: 39907245462.7945\n",
      "Epoch 182/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38808199243.3973 - val_loss: 39907183756.2740\n",
      "Epoch 183/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38808137913.8630 - val_loss: 39907123662.9041\n",
      "Epoch 184/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38808078876.0548 - val_loss: 39907063036.4931\n",
      "Epoch 185/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38808019217.5342 - val_loss: 39907002101.4795\n",
      "Epoch 186/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38807954323.2877 - val_loss: 39906933914.3014\n",
      "Epoch 187/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38807889060.8219 - val_loss: 39906868757.0411\n",
      "Epoch 188/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38807827168.4384 - val_loss: 39906808439.2329\n",
      "Epoch 189/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38807765738.9589 - val_loss: 39906744207.7808\n",
      "Epoch 190/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38807704130.6301 - val_loss: 39906684044.2740\n",
      "Epoch 191/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38807642736.2192 - val_loss: 39906622548.1644\n",
      "Epoch 192/1000\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 38807585546.5205 - val_loss: 39906568472.5479\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 240us/step - loss: 38807529086.2466 - val_loss: 39906507747.9452\n",
      "Epoch 194/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38807466576.6575 - val_loss: 39906443923.2877\n",
      "Epoch 195/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38807404147.7260 - val_loss: 39906379481.4247\n",
      "Epoch 196/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38807339365.6986 - val_loss: 39906314857.2055\n",
      "Epoch 197/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38807275330.6301 - val_loss: 39906249784.1096\n",
      "Epoch 198/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38807210336.4384 - val_loss: 39906186534.5753\n",
      "Epoch 199/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38807147642.7397 - val_loss: 39906118417.5342\n",
      "Epoch 200/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38807083646.2466 - val_loss: 39906056696.9863\n",
      "Epoch 201/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38807025762.1918 - val_loss: 39905999086.4658\n",
      "Epoch 202/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38806965532.0548 - val_loss: 39905938838.7945\n",
      "Epoch 203/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38806902626.1918 - val_loss: 39905874326.7945\n",
      "Epoch 204/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38806839355.6164 - val_loss: 39905809534.2466\n",
      "Epoch 205/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38806775699.2877 - val_loss: 39905744994.1918\n",
      "Epoch 206/1000\n",
      "1168/1168 [==============================] - 0s 219us/step - loss: 38806711618.6301 - val_loss: 39905681323.8356\n",
      "Epoch 207/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38806652005.6986 - val_loss: 39905620304.6575\n",
      "Epoch 208/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38806587970.6301 - val_loss: 39905555007.1233\n",
      "Epoch 209/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38806521173.9178 - val_loss: 39905487381.0411\n",
      "Epoch 210/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38806457475.5069 - val_loss: 39905425183.5616\n",
      "Epoch 211/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38806394531.0685 - val_loss: 39905361723.6164\n",
      "Epoch 212/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38806333176.9863 - val_loss: 39905301279.5616\n",
      "Epoch 213/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38806272936.3288 - val_loss: 39905237104.2192\n",
      "Epoch 214/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38806211790.9041 - val_loss: 39905179283.2877\n",
      "Epoch 215/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38806155518.2466 - val_loss: 39905123061.4795\n",
      "Epoch 216/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38806095773.8082 - val_loss: 39905058058.5205\n",
      "Epoch 217/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38806035056.2192 - val_loss: 39905001640.3288\n",
      "Epoch 218/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38805977498.3014 - val_loss: 39904940565.0411\n",
      "Epoch 219/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38805917930.9589 - val_loss: 39904882884.3836\n",
      "Epoch 220/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38805855635.2877 - val_loss: 39904815538.8493\n",
      "Epoch 221/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38805789646.9041 - val_loss: 39904748740.3836\n",
      "Epoch 222/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38805725461.0411 - val_loss: 39904685546.9589\n",
      "Epoch 223/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38805664068.3836 - val_loss: 39904625692.0548\n",
      "Epoch 224/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38805603775.1233 - val_loss: 39904565318.1370\n",
      "Epoch 225/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38805542691.0685 - val_loss: 39904501156.8219\n",
      "Epoch 226/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38805481382.5753 - val_loss: 39904439169.7534\n",
      "Epoch 227/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38805420673.7534 - val_loss: 39904378851.9452\n",
      "Epoch 228/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38805356326.5753 - val_loss: 39904313792.8767\n",
      "Epoch 229/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38805293799.4521 - val_loss: 39904250459.1781\n",
      "Epoch 230/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38805232696.1096 - val_loss: 39904189299.7260\n",
      "Epoch 231/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38805171564.7123 - val_loss: 39904127943.8904\n",
      "Epoch 232/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38805109353.2055 - val_loss: 39904064413.8082\n",
      "Epoch 233/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38805050715.1781 - val_loss: 39904006312.3288\n",
      "Epoch 234/1000\n",
      "1168/1168 [==============================] - 0s 246us/step - loss: 38804990551.6712 - val_loss: 39903942782.2466\n",
      "Epoch 235/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38804928483.9452 - val_loss: 39903882829.1507\n",
      "Epoch 236/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38804870140.4931 - val_loss: 39903824222.6849\n",
      "Epoch 237/1000\n",
      "1168/1168 [==============================] - 0s 277us/step - loss: 38804807022.4658 - val_loss: 39903760187.6164\n",
      "Epoch 238/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38804747825.0959 - val_loss: 39903703362.6301\n",
      "Epoch 239/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38804692209.9726 - val_loss: 39903646860.2740\n",
      "Epoch 240/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38804637359.3425 - val_loss: 39903592195.5069\n",
      "Epoch 241/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38804580208.2192 - val_loss: 39903532200.3288\n",
      "Epoch 242/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38804518833.0959 - val_loss: 39903467029.0411\n",
      "Epoch 243/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38804453905.5342 - val_loss: 39903402096.2192\n",
      "Epoch 244/1000\n",
      "1168/1168 [==============================] - 0s 264us/step - loss: 38804390591.1233 - val_loss: 39903338636.2740\n",
      "Epoch 245/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38804328183.2329 - val_loss: 39903278037.9178\n",
      "Epoch 246/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38804266075.1781 - val_loss: 39903210117.2603\n",
      "Epoch 247/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38804203351.6712 - val_loss: 39903152296.3288\n",
      "Epoch 248/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38804141403.1781 - val_loss: 39903088275.2877\n",
      "Epoch 249/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38804081043.2877 - val_loss: 39903027480.5479\n",
      "Epoch 250/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38804021235.7260 - val_loss: 39902966405.2603\n",
      "Epoch 251/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38803955133.3699 - val_loss: 39902895468.7123\n",
      "Epoch 252/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38803890453.0411 - val_loss: 39902834042.7397\n",
      "Epoch 253/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38803831032.9863 - val_loss: 39902776348.0548\n",
      "Epoch 254/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38803770143.5616 - val_loss: 39902713098.5205\n",
      "Epoch 255/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38803708693.0411 - val_loss: 39902652093.3699\n",
      "Epoch 256/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38803648729.4247 - val_loss: 39902590597.2603\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 237us/step - loss: 38803586688.0000 - val_loss: 39902526506.0822\n",
      "Epoch 258/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38803523752.3288 - val_loss: 39902462611.2877\n",
      "Epoch 259/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38803459836.4931 - val_loss: 39902396794.7397\n",
      "Epoch 260/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38803398824.3288 - val_loss: 39902344051.7260\n",
      "Epoch 261/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38803342095.7808 - val_loss: 39902282625.7534\n",
      "Epoch 262/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38803284977.9726 - val_loss: 39902226207.5616\n",
      "Epoch 263/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38803226308.3836 - val_loss: 39902162116.3836\n",
      "Epoch 264/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38803163006.2466 - val_loss: 39902097183.5616\n",
      "Epoch 265/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38803099090.4110 - val_loss: 39902036739.5069\n",
      "Epoch 266/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38803036689.5342 - val_loss: 39901969730.6301\n",
      "Epoch 267/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38802973853.8082 - val_loss: 39901910857.6438\n",
      "Epoch 268/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38802910865.5342 - val_loss: 39901842866.8493\n",
      "Epoch 269/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38802845594.3014 - val_loss: 39901778565.2603\n",
      "Epoch 270/1000\n",
      "1168/1168 [==============================] - 0s 265us/step - loss: 38802782439.4521 - val_loss: 39901717910.7945\n",
      "Epoch 271/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38802721970.8493 - val_loss: 39901658027.8356\n",
      "Epoch 272/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38802663399.4521 - val_loss: 39901597247.1233\n",
      "Epoch 273/1000\n",
      "1168/1168 [==============================] - 0s 265us/step - loss: 38802600938.9589 - val_loss: 39901531079.8904\n",
      "Epoch 274/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38802536686.4658 - val_loss: 39901467914.5205\n",
      "Epoch 275/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38802474499.5069 - val_loss: 39901406053.6986\n",
      "Epoch 276/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38802418782.6849 - val_loss: 39901353030.1370\n",
      "Epoch 277/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38802360586.5205 - val_loss: 39901289850.7397\n",
      "Epoch 278/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38802296337.5342 - val_loss: 39901223416.9863\n",
      "Epoch 279/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38802230335.1233 - val_loss: 39901159452.0548\n",
      "Epoch 280/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38802166776.9863 - val_loss: 39901091320.9863\n",
      "Epoch 281/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38802102008.9863 - val_loss: 39901030175.5616\n",
      "Epoch 282/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38802039629.1507 - val_loss: 39900966084.3836\n",
      "Epoch 283/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38801976760.1096 - val_loss: 39900901852.9315\n",
      "Epoch 284/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38801914522.3014 - val_loss: 39900841549.1507\n",
      "Epoch 285/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38801853275.1781 - val_loss: 39900777233.5342\n",
      "Epoch 286/1000\n",
      "1168/1168 [==============================] - 0s 255us/step - loss: 38801789902.9041 - val_loss: 39900714965.9178\n",
      "Epoch 287/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38801730589.8082 - val_loss: 39900655279.3425\n",
      "Epoch 288/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38801669572.3836 - val_loss: 39900591188.1644\n",
      "Epoch 289/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38801609128.3288 - val_loss: 39900533788.0548\n",
      "Epoch 290/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38801549806.4658 - val_loss: 39900470047.5616\n",
      "Epoch 291/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38801486420.1644 - val_loss: 39900407359.1233\n",
      "Epoch 292/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38801421652.1644 - val_loss: 39900340069.6986\n",
      "Epoch 293/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38801358044.9315 - val_loss: 39900278138.7397\n",
      "Epoch 294/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38801295328.4384 - val_loss: 39900214762.9589\n",
      "Epoch 295/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38801233057.3151 - val_loss: 39900151078.5753\n",
      "Epoch 296/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38801169583.3425 - val_loss: 39900089161.6438\n",
      "Epoch 297/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38801104797.8082 - val_loss: 39900021395.2877\n",
      "Epoch 298/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38801041755.1781 - val_loss: 39899964205.5890\n",
      "Epoch 299/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38800989127.8904 - val_loss: 39899911602.8493\n",
      "Epoch 300/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38800933390.0274 - val_loss: 39899855324.9315\n",
      "Epoch 301/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38800875730.4110 - val_loss: 39899793393.9726\n",
      "Epoch 302/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38800812054.7945 - val_loss: 39899725753.8630\n",
      "Epoch 303/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38800748698.3014 - val_loss: 39899664047.3425\n",
      "Epoch 304/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38800686893.5890 - val_loss: 39899600447.1233\n",
      "Epoch 305/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38800623900.0548 - val_loss: 39899535935.1233\n",
      "Epoch 306/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38800561383.4521 - val_loss: 39899474439.0137\n",
      "Epoch 307/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38800498033.9726 - val_loss: 39899410894.9041\n",
      "Epoch 308/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38800435768.1096 - val_loss: 39899348557.1507\n",
      "Epoch 309/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38800371825.9726 - val_loss: 39899280215.6712\n",
      "Epoch 310/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38800307643.6164 - val_loss: 39899217457.0959\n",
      "Epoch 311/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38800243399.8904 - val_loss: 39899155610.3014\n",
      "Epoch 312/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38800181447.8904 - val_loss: 39899088180.6027\n",
      "Epoch 313/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38800118613.9178 - val_loss: 39899030023.0137\n",
      "Epoch 314/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38800058154.0822 - val_loss: 39898970055.8904\n",
      "Epoch 315/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38800000529.5342 - val_loss: 39898909555.7260\n",
      "Epoch 316/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38799940979.7260 - val_loss: 39898849111.6712\n",
      "Epoch 317/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38799880584.7671 - val_loss: 39898787896.1096\n",
      "Epoch 318/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38799818941.3699 - val_loss: 39898723454.2466\n",
      "Epoch 319/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38799756579.0685 - val_loss: 39898662238.6849\n",
      "Epoch 320/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38799694462.2466 - val_loss: 39898598919.0137\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 235us/step - loss: 38799633173.0411 - val_loss: 39898540312.5479\n",
      "Epoch 322/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38799571985.5342 - val_loss: 39898476487.8904\n",
      "Epoch 323/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38799509581.1507 - val_loss: 39898412088.1096\n",
      "Epoch 324/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38799444462.4658 - val_loss: 39898347365.6986\n",
      "Epoch 325/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38799381276.0548 - val_loss: 39898284466.8493\n",
      "Epoch 326/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38799317774.0274 - val_loss: 39898221568.0000\n",
      "Epoch 327/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38799256183.2329 - val_loss: 39898158374.5753\n",
      "Epoch 328/1000\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 38799195788.2740 - val_loss: 39898096597.9178\n",
      "Epoch 329/1000\n",
      "1168/1168 [==============================] - 0s 271us/step - loss: 38799134525.3699 - val_loss: 39898035789.1507\n",
      "Epoch 330/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38799075464.7671 - val_loss: 39897975443.2877\n",
      "Epoch 331/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38799016974.0274 - val_loss: 39897918954.9589\n",
      "Epoch 332/1000\n",
      "1168/1168 [==============================] - 0s 336us/step - loss: 38798959324.9315 - val_loss: 39897857739.3973\n",
      "Epoch 333/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38798898614.3562 - val_loss: 39897793788.4931\n",
      "Epoch 334/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38798831731.7260 - val_loss: 39897727761.5342\n",
      "Epoch 335/1000\n",
      "1168/1168 [==============================] - 0s 309us/step - loss: 38798767833.4247 - val_loss: 39897665073.0959\n",
      "Epoch 336/1000\n",
      "1168/1168 [==============================] - 0s 324us/step - loss: 38798709574.1370 - val_loss: 39897607111.8904\n",
      "Epoch 337/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38798651206.1370 - val_loss: 39897549711.7808\n",
      "Epoch 338/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38798591701.9178 - val_loss: 39897486027.3973\n",
      "Epoch 339/1000\n",
      "1168/1168 [==============================] - 0s 348us/step - loss: 38798528859.1781 - val_loss: 39897424952.1096\n",
      "Epoch 340/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38798466040.9863 - val_loss: 39897360790.7945\n",
      "Epoch 341/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38798403173.6986 - val_loss: 39897299224.5479\n",
      "Epoch 342/1000\n",
      "1168/1168 [==============================] - 0s 278us/step - loss: 38798343981.5890 - val_loss: 39897235484.0548\n",
      "Epoch 343/1000\n",
      "1168/1168 [==============================] - 0s 348us/step - loss: 38798279448.5479 - val_loss: 39897170228.6027\n",
      "Epoch 344/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38798212117.0411 - val_loss: 39897101606.5753\n",
      "Epoch 345/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38798146791.4521 - val_loss: 39897037866.0822\n",
      "Epoch 346/1000\n",
      "1168/1168 [==============================] - 0s 295us/step - loss: 38798085130.5205 - val_loss: 39896977211.6164\n",
      "Epoch 347/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38798022620.9315 - val_loss: 39896911857.9726\n",
      "Epoch 348/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38797956874.5205 - val_loss: 39896844919.2329\n",
      "Epoch 349/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38797890423.2329 - val_loss: 39896777138.8493\n",
      "Epoch 350/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38797826233.8630 - val_loss: 39896714730.9589\n",
      "Epoch 351/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38797768423.4521 - val_loss: 39896660865.7534\n",
      "Epoch 352/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38797713022.2466 - val_loss: 39896602245.2603\n",
      "Epoch 353/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38797655250.4110 - val_loss: 39896543302.1370\n",
      "Epoch 354/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38797594662.5753 - val_loss: 39896480543.5616\n",
      "Epoch 355/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38797530126.0274 - val_loss: 39896416382.2466\n",
      "Epoch 356/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38797465799.8904 - val_loss: 39896350776.1096\n",
      "Epoch 357/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38797405895.8904 - val_loss: 39896292871.0137\n",
      "Epoch 358/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38797346468.8219 - val_loss: 39896230182.5753\n",
      "Epoch 359/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38797288581.2603 - val_loss: 39896172852.6027\n",
      "Epoch 360/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38797228750.9041 - val_loss: 39896111075.9452\n",
      "Epoch 361/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38797166648.1096 - val_loss: 39896046914.6301\n",
      "Epoch 362/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38797104682.0822 - val_loss: 39895990145.7534\n",
      "Epoch 363/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38797046591.1233 - val_loss: 39895926391.2329\n",
      "Epoch 364/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38796982114.1918 - val_loss: 39895861556.6027\n",
      "Epoch 365/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38796923072.8767 - val_loss: 39895804451.0685\n",
      "Epoch 366/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38796863859.7260 - val_loss: 39895744301.5890\n",
      "Epoch 367/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38796803419.1781 - val_loss: 39895682314.5205\n",
      "Epoch 368/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38796740730.7397 - val_loss: 39895618994.8493\n",
      "Epoch 369/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38796676225.7534 - val_loss: 39895553753.4247\n",
      "Epoch 370/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38796610191.7808 - val_loss: 39895485832.7671\n",
      "Epoch 371/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38796548892.0548 - val_loss: 39895428067.9452\n",
      "Epoch 372/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38796489387.8356 - val_loss: 39895364832.4384\n",
      "Epoch 373/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38796426548.6027 - val_loss: 39895300306.4110\n",
      "Epoch 374/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38796361422.9041 - val_loss: 39895234854.5753\n",
      "Epoch 375/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38796296914.4110 - val_loss: 39895171114.0822\n",
      "Epoch 376/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38796232546.1918 - val_loss: 39895101790.6849\n",
      "Epoch 377/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38796167385.4247 - val_loss: 39895041402.7397\n",
      "Epoch 378/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38796110058.9589 - val_loss: 39894984213.0411\n",
      "Epoch 379/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38796052578.1918 - val_loss: 39894923656.7671\n",
      "Epoch 380/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38795991232.8767 - val_loss: 39894862791.8904\n",
      "Epoch 381/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38795930010.3014 - val_loss: 39894802488.1096\n",
      "Epoch 382/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38795868195.0685 - val_loss: 39894737835.8356\n",
      "Epoch 383/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38795802648.5479 - val_loss: 39894669915.1781\n",
      "Epoch 384/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38795736183.2329 - val_loss: 39894605669.6986\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 232us/step - loss: 38795677173.4795 - val_loss: 39894544874.9589\n",
      "Epoch 386/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38795614940.9315 - val_loss: 39894482817.7534\n",
      "Epoch 387/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38795551775.5616 - val_loss: 39894419007.1233\n",
      "Epoch 388/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38795491685.6986 - val_loss: 39894362027.8356\n",
      "Epoch 389/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38795436480.8767 - val_loss: 39894305539.5069\n",
      "Epoch 390/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38795377278.2466 - val_loss: 39894241378.1918\n",
      "Epoch 391/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38795314803.7260 - val_loss: 39894179250.8493\n",
      "Epoch 392/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38795253805.5890 - val_loss: 39894119914.9589\n",
      "Epoch 393/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38795193417.6438 - val_loss: 39894058026.0822\n",
      "Epoch 394/1000\n",
      "1168/1168 [==============================] - 0s 221us/step - loss: 38795131465.6438 - val_loss: 39893993472.0000\n",
      "Epoch 395/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38795067960.1096 - val_loss: 39893929941.9178\n",
      "Epoch 396/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38795006106.3014 - val_loss: 39893868024.9863\n",
      "Epoch 397/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38794942148.3836 - val_loss: 39893804144.2192\n",
      "Epoch 398/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38794879989.4795 - val_loss: 39893742858.5205\n",
      "Epoch 399/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38794822887.4521 - val_loss: 39893685724.9315\n",
      "Epoch 400/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38794762909.8082 - val_loss: 39893622531.5069\n",
      "Epoch 401/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38794702030.9041 - val_loss: 39893564023.2329\n",
      "Epoch 402/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38794644087.2329 - val_loss: 39893503915.8356\n",
      "Epoch 403/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38794583715.0685 - val_loss: 39893443850.5205\n",
      "Epoch 404/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38794523272.7671 - val_loss: 39893382424.5479\n",
      "Epoch 405/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38794462723.5069 - val_loss: 39893319385.4247\n",
      "Epoch 406/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38794398674.4110 - val_loss: 39893256837.2603\n",
      "Epoch 407/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38794334623.5616 - val_loss: 39893188706.1918\n",
      "Epoch 408/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38794272112.2192 - val_loss: 39893127981.5890\n",
      "Epoch 409/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38794207060.1644 - val_loss: 39893059569.9726\n",
      "Epoch 410/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38794139525.2603 - val_loss: 39892991172.3836\n",
      "Epoch 411/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38794072786.4110 - val_loss: 39892927221.4795\n",
      "Epoch 412/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38794008512.8767 - val_loss: 39892863607.2329\n",
      "Epoch 413/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38793949534.6849 - val_loss: 39892802377.6438\n",
      "Epoch 414/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38793888575.1233 - val_loss: 39892740741.2603\n",
      "Epoch 415/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38793825090.6301 - val_loss: 39892676930.6301\n",
      "Epoch 416/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38793761732.3836 - val_loss: 39892609164.2740\n",
      "Epoch 417/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38793695680.8767 - val_loss: 39892544652.2740\n",
      "Epoch 418/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38793630846.2466 - val_loss: 39892478765.5890\n",
      "Epoch 419/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38793566449.9726 - val_loss: 39892415081.2055\n",
      "Epoch 420/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38793504890.7397 - val_loss: 39892354076.0548\n",
      "Epoch 421/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38793441507.9452 - val_loss: 39892289564.0548\n",
      "Epoch 422/1000\n",
      "1168/1168 [==============================] - 0s 256us/step - loss: 38793379441.9726 - val_loss: 39892228979.7260\n",
      "Epoch 423/1000\n",
      "1168/1168 [==============================] - 0s 252us/step - loss: 38793319557.2603 - val_loss: 39892164313.4247\n",
      "Epoch 424/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38793257713.9726 - val_loss: 39892104234.0822\n",
      "Epoch 425/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38793194369.7534 - val_loss: 39892039708.0548\n",
      "Epoch 426/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38793131490.1918 - val_loss: 39891978478.4658\n",
      "Epoch 427/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38793072149.0411 - val_loss: 39891914667.8356\n",
      "Epoch 428/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38793009376.4384 - val_loss: 39891853592.5479\n",
      "Epoch 429/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38792949386.5205 - val_loss: 39891795771.6164\n",
      "Epoch 430/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38792892138.9589 - val_loss: 39891739072.8767\n",
      "Epoch 431/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38792836173.1507 - val_loss: 39891679919.3425\n",
      "Epoch 432/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38792775978.0822 - val_loss: 39891617988.3836\n",
      "Epoch 433/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38792712826.7397 - val_loss: 39891549857.3151\n",
      "Epoch 434/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38792648756.6027 - val_loss: 39891489132.7123\n",
      "Epoch 435/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38792585608.7671 - val_loss: 39891424760.9863\n",
      "Epoch 436/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38792521998.0274 - val_loss: 39891361020.4931\n",
      "Epoch 437/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38792461126.1370 - val_loss: 39891299173.6986\n",
      "Epoch 438/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38792400859.1781 - val_loss: 39891241843.7260\n",
      "Epoch 439/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38792339662.9041 - val_loss: 39891174203.6164\n",
      "Epoch 440/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38792277074.4110 - val_loss: 39891116663.2329\n",
      "Epoch 441/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38792213640.7671 - val_loss: 39891048952.9863\n",
      "Epoch 442/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38792150805.0411 - val_loss: 39890987176.3288\n",
      "Epoch 443/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38792088397.1507 - val_loss: 39890923576.1096\n",
      "Epoch 444/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38792027854.9041 - val_loss: 39890863132.0548\n",
      "Epoch 445/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38791964580.8219 - val_loss: 39890797778.4110\n",
      "Epoch 446/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38791899093.9178 - val_loss: 39890733673.2055\n",
      "Epoch 447/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38791838351.7808 - val_loss: 39890672738.1918\n",
      "Epoch 448/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38791775056.6575 - val_loss: 39890604887.6712\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 231us/step - loss: 38791709368.1096 - val_loss: 39890541427.7260\n",
      "Epoch 450/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38791644170.5205 - val_loss: 39890472328.7671\n",
      "Epoch 451/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38791578851.9452 - val_loss: 39890411534.0274\n",
      "Epoch 452/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38791519870.2466 - val_loss: 39890353979.6164\n",
      "Epoch 453/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38791462505.2055 - val_loss: 39890294082.6301\n",
      "Epoch 454/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38791402571.3973 - val_loss: 39890233119.5616\n",
      "Epoch 455/1000\n",
      "1168/1168 [==============================] - 0s 222us/step - loss: 38791341799.4521 - val_loss: 39890171048.3288\n",
      "Epoch 456/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38791279358.2466 - val_loss: 39890110674.4110\n",
      "Epoch 457/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38791221314.6301 - val_loss: 39890050258.4110\n",
      "Epoch 458/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38791161820.9315 - val_loss: 39889991006.6849\n",
      "Epoch 459/1000\n",
      "1168/1168 [==============================] - 0s 223us/step - loss: 38791104277.0411 - val_loss: 39889933185.7534\n",
      "Epoch 460/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38791045053.3699 - val_loss: 39889871198.6849\n",
      "Epoch 461/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38790982172.0548 - val_loss: 39889806812.9315\n",
      "Epoch 462/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38790920339.2877 - val_loss: 39889747126.3562\n",
      "Epoch 463/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38790860624.6575 - val_loss: 39889682684.4931\n",
      "Epoch 464/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38790799382.7945 - val_loss: 39889625214.2466\n",
      "Epoch 465/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38790740311.6712 - val_loss: 39889561614.0274\n",
      "Epoch 466/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38790676848.2192 - val_loss: 39889499977.6438\n",
      "Epoch 467/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38790615124.1644 - val_loss: 39889435956.6027\n",
      "Epoch 468/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38790551082.0822 - val_loss: 39889375288.1096\n",
      "Epoch 469/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38790487944.7671 - val_loss: 39889307648.0000\n",
      "Epoch 470/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38790422657.7534 - val_loss: 39889242294.3562\n",
      "Epoch 471/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38790359471.3425 - val_loss: 39889180517.6986\n",
      "Epoch 472/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38790296891.6164 - val_loss: 39889114013.8082\n",
      "Epoch 473/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38790234052.3836 - val_loss: 39889052026.7397\n",
      "Epoch 474/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38790172922.7397 - val_loss: 39888992578.6301\n",
      "Epoch 475/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38790113991.8904 - val_loss: 39888930942.2466\n",
      "Epoch 476/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38790052134.5753 - val_loss: 39888870133.4795\n",
      "Epoch 477/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38789993221.2603 - val_loss: 39888813154.1918\n",
      "Epoch 478/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38789935374.0274 - val_loss: 39888753088.8767\n",
      "Epoch 479/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38789875491.0685 - val_loss: 39888691312.2192\n",
      "Epoch 480/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38789814031.7808 - val_loss: 39888628343.2329\n",
      "Epoch 481/1000\n",
      "1168/1168 [==============================] - 0s 252us/step - loss: 38789752919.6712 - val_loss: 39888567057.5342\n",
      "Epoch 482/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38789693573.2603 - val_loss: 39888509096.3288\n",
      "Epoch 483/1000\n",
      "1168/1168 [==============================] - 0s 264us/step - loss: 38789631628.2740 - val_loss: 39888442087.4521\n",
      "Epoch 484/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38789566165.9178 - val_loss: 39888378403.0685\n",
      "Epoch 485/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38789501022.6849 - val_loss: 39888311829.0411\n",
      "Epoch 486/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38789437482.0822 - val_loss: 39888248018.4110\n",
      "Epoch 487/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38789374748.0548 - val_loss: 39888183927.2329\n",
      "Epoch 488/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38789310712.9863 - val_loss: 39888118601.6438\n",
      "Epoch 489/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38789246067.7260 - val_loss: 39888055141.6986\n",
      "Epoch 490/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38789185874.4110 - val_loss: 39887998092.2740\n",
      "Epoch 491/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38789127076.8219 - val_loss: 39887936371.7260\n",
      "Epoch 492/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38789064048.2192 - val_loss: 39887871088.2192\n",
      "Epoch 493/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38788999031.2329 - val_loss: 39887805285.6986\n",
      "Epoch 494/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38788936993.3151 - val_loss: 39887743298.6301\n",
      "Epoch 495/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38788874853.6986 - val_loss: 39887682882.6301\n",
      "Epoch 496/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38788813052.4931 - val_loss: 39887617136.2192\n",
      "Epoch 497/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38788749804.7123 - val_loss: 39887554083.0685\n",
      "Epoch 498/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38788690130.4110 - val_loss: 39887496823.2329\n",
      "Epoch 499/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38788636375.6712 - val_loss: 39887444515.0685\n",
      "Epoch 500/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38788578835.2877 - val_loss: 39887383145.2055\n",
      "Epoch 501/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38788518394.7397 - val_loss: 39887321508.8219\n",
      "Epoch 502/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38788453372.4931 - val_loss: 39887252830.6849\n",
      "Epoch 503/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38788388155.6164 - val_loss: 39887189637.2603\n",
      "Epoch 504/1000\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 38788325551.3425 - val_loss: 39887128000.8767\n",
      "Epoch 505/1000\n",
      "1168/1168 [==============================] - 0s 374us/step - loss: 38788264027.1781 - val_loss: 39887064035.9452\n",
      "Epoch 506/1000\n",
      "1168/1168 [==============================] - 0s 424us/step - loss: 38788199867.6164 - val_loss: 39886996550.1370\n",
      "Epoch 507/1000\n",
      "1168/1168 [==============================] - 0s 409us/step - loss: 38788134354.4110 - val_loss: 39886931547.1781\n",
      "Epoch 508/1000\n",
      "1168/1168 [==============================] - 0s 325us/step - loss: 38788070410.5205 - val_loss: 39886871243.3973\n",
      "Epoch 509/1000\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 38788011541.0411 - val_loss: 39886810659.0685\n",
      "Epoch 510/1000\n",
      "1168/1168 [==============================] - 0s 312us/step - loss: 38787950164.1644 - val_loss: 39886748826.3014\n",
      "Epoch 511/1000\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 38787890019.9452 - val_loss: 39886687316.1644\n",
      "Epoch 512/1000\n",
      "1168/1168 [==============================] - 0s 380us/step - loss: 38787827582.2466 - val_loss: 39886624922.3014\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 332us/step - loss: 38787764332.7123 - val_loss: 39886558544.6575\n",
      "Epoch 514/1000\n",
      "1168/1168 [==============================] - 0s 330us/step - loss: 38787697744.6575 - val_loss: 39886494032.6575\n",
      "Epoch 515/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38787635035.1781 - val_loss: 39886427178.0822\n",
      "Epoch 516/1000\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 38787570679.2329 - val_loss: 39886365176.9863\n",
      "Epoch 517/1000\n",
      "1168/1168 [==============================] - 0s 300us/step - loss: 38787507178.9589 - val_loss: 39886300931.5069\n",
      "Epoch 518/1000\n",
      "1168/1168 [==============================] - 0s 279us/step - loss: 38787444743.0137 - val_loss: 39886236559.7808\n",
      "Epoch 519/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38787379747.0685 - val_loss: 39886175414.3562\n",
      "Epoch 520/1000\n",
      "1168/1168 [==============================] - 0s 295us/step - loss: 38787319127.6712 - val_loss: 39886108700.0548\n",
      "Epoch 521/1000\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 38787253714.4110 - val_loss: 39886046418.4110\n",
      "Epoch 522/1000\n",
      "1168/1168 [==============================] - 0s 252us/step - loss: 38787191459.0685 - val_loss: 39885981990.5753\n",
      "Epoch 523/1000\n",
      "1168/1168 [==============================] - 0s 263us/step - loss: 38787130266.3014 - val_loss: 39885921462.3562\n",
      "Epoch 524/1000\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 38787069520.6575 - val_loss: 39885857427.2877\n",
      "Epoch 525/1000\n",
      "1168/1168 [==============================] - 0s 324us/step - loss: 38787006660.3836 - val_loss: 39885796141.5890\n",
      "Epoch 526/1000\n",
      "1168/1168 [==============================] - 0s 285us/step - loss: 38786944173.5890 - val_loss: 39885731559.4521\n",
      "Epoch 527/1000\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 38786880238.4658 - val_loss: 39885668309.9178\n",
      "Epoch 528/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38786816483.9452 - val_loss: 39885603054.4658\n",
      "Epoch 529/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38786753136.2192 - val_loss: 39885539243.8356\n",
      "Epoch 530/1000\n",
      "1168/1168 [==============================] - 0s 268us/step - loss: 38786693639.0137 - val_loss: 39885481002.0822\n",
      "Epoch 531/1000\n",
      "1168/1168 [==============================] - 0s 249us/step - loss: 38786634245.2603 - val_loss: 39885424710.1370\n",
      "Epoch 532/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38786579108.8219 - val_loss: 39885366762.9589\n",
      "Epoch 533/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38786517696.8767 - val_loss: 39885300104.7671\n",
      "Epoch 534/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38786452615.0137 - val_loss: 39885235943.4521\n",
      "Epoch 535/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38786390889.2055 - val_loss: 39885174236.9315\n",
      "Epoch 536/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38786330676.6027 - val_loss: 39885116626.4110\n",
      "Epoch 537/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38786271014.5753 - val_loss: 39885053362.8493\n",
      "Epoch 538/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38786209476.3836 - val_loss: 39884991081.2055\n",
      "Epoch 539/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38786146563.5069 - val_loss: 39884928392.7671\n",
      "Epoch 540/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38786085137.5342 - val_loss: 39884867107.0685\n",
      "Epoch 541/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38786028337.0959 - val_loss: 39884810548.6027\n",
      "Epoch 542/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38785967921.0959 - val_loss: 39884745896.3288\n",
      "Epoch 543/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38785904822.3562 - val_loss: 39884684750.9041\n",
      "Epoch 544/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38785842389.9178 - val_loss: 39884619747.9452\n",
      "Epoch 545/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38785777804.2740 - val_loss: 39884552668.9315\n",
      "Epoch 546/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38785713162.5205 - val_loss: 39884490457.4247\n",
      "Epoch 547/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38785649839.3425 - val_loss: 39884424093.8082\n",
      "Epoch 548/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38785585588.6027 - val_loss: 39884360914.4110\n",
      "Epoch 549/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38785522389.9178 - val_loss: 39884297244.0548\n",
      "Epoch 550/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38785460595.7260 - val_loss: 39884236365.1507\n",
      "Epoch 551/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38785398741.9178 - val_loss: 39884172750.9041\n",
      "Epoch 552/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38785335930.7397 - val_loss: 39884110553.4247\n",
      "Epoch 553/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38785273336.9863 - val_loss: 39884046742.7945\n",
      "Epoch 554/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38785211407.7808 - val_loss: 39883985457.0959\n",
      "Epoch 555/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38785150660.3836 - val_loss: 39883922628.3836\n",
      "Epoch 556/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38785091608.5479 - val_loss: 39883865088.0000\n",
      "Epoch 557/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38785033002.0822 - val_loss: 39883807617.7534\n",
      "Epoch 558/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38784977937.5342 - val_loss: 39883750638.4658\n",
      "Epoch 559/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38784917055.1233 - val_loss: 39883686883.9452\n",
      "Epoch 560/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38784853442.6301 - val_loss: 39883622890.9589\n",
      "Epoch 561/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38784791888.6575 - val_loss: 39883557537.3151\n",
      "Epoch 562/1000\n",
      "1168/1168 [==============================] - 0s 318us/step - loss: 38784727527.4521 - val_loss: 39883496602.3014\n",
      "Epoch 563/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38784669825.7534 - val_loss: 39883438991.7808\n",
      "Epoch 564/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38784607971.9452 - val_loss: 39883375251.2877\n",
      "Epoch 565/1000\n",
      "1168/1168 [==============================] - 0s 383us/step - loss: 38784544396.2740 - val_loss: 39883307681.3151\n",
      "Epoch 566/1000\n",
      "1168/1168 [==============================] - 0s 262us/step - loss: 38784481770.9589 - val_loss: 39883250000.6575\n",
      "Epoch 567/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38784420732.4931 - val_loss: 39883185965.5890\n",
      "Epoch 568/1000\n",
      "1168/1168 [==============================] - 0s 295us/step - loss: 38784356348.4931 - val_loss: 39883120934.5753\n",
      "Epoch 569/1000\n",
      "1168/1168 [==============================] - 0s 331us/step - loss: 38784293070.9041 - val_loss: 39883056562.8493\n",
      "Epoch 570/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38784227001.8630 - val_loss: 39882988375.6712\n",
      "Epoch 571/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38784163054.4658 - val_loss: 39882924144.2192\n",
      "Epoch 572/1000\n",
      "1168/1168 [==============================] - 0s 348us/step - loss: 38784096985.4247 - val_loss: 39882858327.6712\n",
      "Epoch 573/1000\n",
      "1168/1168 [==============================] - 0s 268us/step - loss: 38784036010.0822 - val_loss: 39882799230.2466\n",
      "Epoch 574/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38783973849.4247 - val_loss: 39882733708.2740\n",
      "Epoch 575/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38783910175.5616 - val_loss: 39882669546.9589\n",
      "Epoch 576/1000\n",
      "1168/1168 [==============================] - 0s 371us/step - loss: 38783845786.3014 - val_loss: 39882600995.0685\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 239us/step - loss: 38783783308.2740 - val_loss: 39882545222.1370\n",
      "Epoch 578/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38783722517.0411 - val_loss: 39882480625.9726\n",
      "Epoch 579/1000\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 38783660168.7671 - val_loss: 39882418554.7397\n",
      "Epoch 580/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38783596908.7123 - val_loss: 39882354323.2877\n",
      "Epoch 581/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38783536387.5069 - val_loss: 39882294019.5069\n",
      "Epoch 582/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38783474523.1781 - val_loss: 39882230629.6986\n",
      "Epoch 583/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38783413959.8904 - val_loss: 39882168572.4931\n",
      "Epoch 584/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38783352839.0137 - val_loss: 39882107707.6164\n",
      "Epoch 585/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38783293824.0000 - val_loss: 39882050854.5753\n",
      "Epoch 586/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38783236271.3425 - val_loss: 39881990789.2603\n",
      "Epoch 587/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38783173944.1096 - val_loss: 39881928661.9178\n",
      "Epoch 588/1000\n",
      "1168/1168 [==============================] - 0s 352us/step - loss: 38783110978.6301 - val_loss: 39881861512.7671\n",
      "Epoch 589/1000\n",
      "1168/1168 [==============================] - 0s 326us/step - loss: 38783047890.4110 - val_loss: 39881800788.1644\n",
      "Epoch 590/1000\n",
      "1168/1168 [==============================] - 0s 322us/step - loss: 38782985384.3288 - val_loss: 39881735925.4795\n",
      "Epoch 591/1000\n",
      "1168/1168 [==============================] - 0s 368us/step - loss: 38782923733.9178 - val_loss: 39881679156.6027\n",
      "Epoch 592/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38782868066.1918 - val_loss: 39881623018.9589\n",
      "Epoch 593/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38782807225.8630 - val_loss: 39881558226.4110\n",
      "Epoch 594/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38782744621.5890 - val_loss: 39881496155.1781\n",
      "Epoch 595/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38782683746.1918 - val_loss: 39881432681.2055\n",
      "Epoch 596/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38782621297.9726 - val_loss: 39881371605.9178\n",
      "Epoch 597/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38782563627.8356 - val_loss: 39881315257.8630\n",
      "Epoch 598/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38782510583.2329 - val_loss: 39881261953.7534\n",
      "Epoch 599/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38782453518.0274 - val_loss: 39881201579.8356\n",
      "Epoch 600/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38782392642.6301 - val_loss: 39881139662.9041\n",
      "Epoch 601/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38782331356.9315 - val_loss: 39881079597.5890\n",
      "Epoch 602/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38782272038.5753 - val_loss: 39881019153.5342\n",
      "Epoch 603/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38782210900.1644 - val_loss: 39880958204.4931\n",
      "Epoch 604/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38782150077.3699 - val_loss: 39880893201.5342\n",
      "Epoch 605/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38782086182.5753 - val_loss: 39880829587.2877\n",
      "Epoch 606/1000\n",
      "1168/1168 [==============================] - 0s 246us/step - loss: 38782021621.4795 - val_loss: 39880763223.6712\n",
      "Epoch 607/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38781957312.8767 - val_loss: 39880699693.5890\n",
      "Epoch 608/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38781895494.1370 - val_loss: 39880637566.2466\n",
      "Epoch 609/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38781830978.6301 - val_loss: 39880570641.5342\n",
      "Epoch 610/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38781765740.7123 - val_loss: 39880505975.2329\n",
      "Epoch 611/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38781703111.8904 - val_loss: 39880442851.9452\n",
      "Epoch 612/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38781639276.7123 - val_loss: 39880377610.5205\n",
      "Epoch 613/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38781573870.4658 - val_loss: 39880312817.9726\n",
      "Epoch 614/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38781511943.0137 - val_loss: 39880252233.6438\n",
      "Epoch 615/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38781450112.0000 - val_loss: 39880188689.5342\n",
      "Epoch 616/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38781387737.4247 - val_loss: 39880123616.4384\n",
      "Epoch 617/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38781325229.5890 - val_loss: 39880062807.6712\n",
      "Epoch 618/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38781265288.7671 - val_loss: 39880005337.4247\n",
      "Epoch 619/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38781209403.6164 - val_loss: 39879948849.0959\n",
      "Epoch 620/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38781149703.0137 - val_loss: 39879884828.0548\n",
      "Epoch 621/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38781087126.7945 - val_loss: 39879819165.8082\n",
      "Epoch 622/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38781024038.5753 - val_loss: 39879761835.8356\n",
      "Epoch 623/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38780970113.7534 - val_loss: 39879708391.4521\n",
      "Epoch 624/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38780914845.8082 - val_loss: 39879648508.4931\n",
      "Epoch 625/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38780853146.3014 - val_loss: 39879584403.2877\n",
      "Epoch 626/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38780788697.4247 - val_loss: 39879520031.5616\n",
      "Epoch 627/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38780725823.1233 - val_loss: 39879455968.4384\n",
      "Epoch 628/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38780661405.8082 - val_loss: 39879391035.6164\n",
      "Epoch 629/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38780599064.5479 - val_loss: 39879333074.4110\n",
      "Epoch 630/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38780540016.2192 - val_loss: 39879270315.8356\n",
      "Epoch 631/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38780478165.9178 - val_loss: 39879208398.9041\n",
      "Epoch 632/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38780415316.1644 - val_loss: 39879144784.6575\n",
      "Epoch 633/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38780353178.3014 - val_loss: 39879083358.6849\n",
      "Epoch 634/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38780290167.2329 - val_loss: 39879015788.7123\n",
      "Epoch 635/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38780228227.5069 - val_loss: 39878958178.1918\n",
      "Epoch 636/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38780168458.5205 - val_loss: 39878896822.3562\n",
      "Epoch 637/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38780108614.1370 - val_loss: 39878833432.5479\n",
      "Epoch 638/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38780047461.6986 - val_loss: 39878772707.9452\n",
      "Epoch 639/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38779985912.9863 - val_loss: 39878712067.5069\n",
      "Epoch 640/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38779923922.4110 - val_loss: 39878650781.8082\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 251us/step - loss: 38779863106.6301 - val_loss: 39878587658.5205\n",
      "Epoch 642/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38779801259.8356 - val_loss: 39878526232.5479\n",
      "Epoch 643/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38779738936.1096 - val_loss: 39878461720.5479\n",
      "Epoch 644/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38779675939.0685 - val_loss: 39878396479.1233\n",
      "Epoch 645/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38779612877.1507 - val_loss: 39878332738.6301\n",
      "Epoch 646/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38779550551.6712 - val_loss: 39878271789.5890\n",
      "Epoch 647/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38779488992.4384 - val_loss: 39878208806.5753\n",
      "Epoch 648/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38779426556.4931 - val_loss: 39878145977.8630\n",
      "Epoch 649/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38779362395.1781 - val_loss: 39878081115.1781\n",
      "Epoch 650/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38779297090.6301 - val_loss: 39878014120.3288\n",
      "Epoch 651/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38779232357.6986 - val_loss: 39877946424.1096\n",
      "Epoch 652/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38779166688.4384 - val_loss: 39877883651.5069\n",
      "Epoch 653/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38779104568.1096 - val_loss: 39877819967.1233\n",
      "Epoch 654/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38779041679.7808 - val_loss: 39877758471.0137\n",
      "Epoch 655/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38778980562.4110 - val_loss: 39877695081.2055\n",
      "Epoch 656/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38778916295.8904 - val_loss: 39877633374.6849\n",
      "Epoch 657/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38778855751.8904 - val_loss: 39877570055.0137\n",
      "Epoch 658/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38778797140.1644 - val_loss: 39877513566.6849\n",
      "Epoch 659/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38778737514.9589 - val_loss: 39877452196.8219\n",
      "Epoch 660/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38778677670.5753 - val_loss: 39877387390.2466\n",
      "Epoch 661/1000\n",
      "1168/1168 [==============================] - 0s 250us/step - loss: 38778614773.4795 - val_loss: 39877329513.2055\n",
      "Epoch 662/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38778557404.9315 - val_loss: 39877269405.8082\n",
      "Epoch 663/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38778499057.9726 - val_loss: 39877212496.6575\n",
      "Epoch 664/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38778439921.9726 - val_loss: 39877149738.0822\n",
      "Epoch 665/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38778379109.6986 - val_loss: 39877090584.5479\n",
      "Epoch 666/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38778316684.2740 - val_loss: 39877028316.9315\n",
      "Epoch 667/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38778258168.9863 - val_loss: 39876970846.6849\n",
      "Epoch 668/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38778200635.6164 - val_loss: 39876909056.0000\n",
      "Epoch 669/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38778138676.6027 - val_loss: 39876845455.7808\n",
      "Epoch 670/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38778073422.9041 - val_loss: 39876780340.6027\n",
      "Epoch 671/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38778013110.3562 - val_loss: 39876720696.1096\n",
      "Epoch 672/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38777950779.6164 - val_loss: 39876655384.5479\n",
      "Epoch 673/1000\n",
      "1168/1168 [==============================] - 0s 252us/step - loss: 38777886025.6438 - val_loss: 39876591153.0959\n",
      "Epoch 674/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38777828004.8219 - val_loss: 39876534103.6712\n",
      "Epoch 675/1000\n",
      "1168/1168 [==============================] - 0s 304us/step - loss: 38777768584.7671 - val_loss: 39876473224.7671\n",
      "Epoch 676/1000\n",
      "1168/1168 [==============================] - 0s 269us/step - loss: 38777704739.0685 - val_loss: 39876407744.8767\n",
      "Epoch 677/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38777638463.1233 - val_loss: 39876339894.3562\n",
      "Epoch 678/1000\n",
      "1168/1168 [==============================] - 0s 246us/step - loss: 38777575097.8630 - val_loss: 39876276280.1096\n",
      "Epoch 679/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38777509996.7123 - val_loss: 39876211810.1918\n",
      "Epoch 680/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38777447923.7260 - val_loss: 39876146947.5069\n",
      "Epoch 681/1000\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 38777383588.8219 - val_loss: 39876082070.7945\n",
      "Epoch 682/1000\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 38777316723.7260 - val_loss: 39876014921.6438\n",
      "Epoch 683/1000\n",
      "1168/1168 [==============================] - 0s 275us/step - loss: 38777250465.3151 - val_loss: 39875948558.0274\n",
      "Epoch 684/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38777186374.1370 - val_loss: 39875884887.6712\n",
      "Epoch 685/1000\n",
      "1168/1168 [==============================] - 0s 269us/step - loss: 38777122619.6164 - val_loss: 39875820165.2603\n",
      "Epoch 686/1000\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 38777059352.5479 - val_loss: 39875759089.9726\n",
      "Epoch 687/1000\n",
      "1168/1168 [==============================] - 0s 265us/step - loss: 38776998550.7945 - val_loss: 39875695966.6849\n",
      "Epoch 688/1000\n",
      "1168/1168 [==============================] - 0s 312us/step - loss: 38776937166.9041 - val_loss: 39875634610.8493\n",
      "Epoch 689/1000\n",
      "1168/1168 [==============================] - 0s 256us/step - loss: 38776876445.8082 - val_loss: 39875573170.8493\n",
      "Epoch 690/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38776815023.3425 - val_loss: 39875510622.6849\n",
      "Epoch 691/1000\n",
      "1168/1168 [==============================] - 0s 264us/step - loss: 38776752334.9041 - val_loss: 39875447934.2466\n",
      "Epoch 692/1000\n",
      "1168/1168 [==============================] - 0s 255us/step - loss: 38776689618.4110 - val_loss: 39875383843.0685\n",
      "Epoch 693/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38776626505.6438 - val_loss: 39875316287.1233\n",
      "Epoch 694/1000\n",
      "1168/1168 [==============================] - 0s 258us/step - loss: 38776562260.1644 - val_loss: 39875255057.5342\n",
      "Epoch 695/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38776498565.2603 - val_loss: 39875190601.6438\n",
      "Epoch 696/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38776436472.9863 - val_loss: 39875133131.3973\n",
      "Epoch 697/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38776379665.5342 - val_loss: 39875072827.6164\n",
      "Epoch 698/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38776318558.6849 - val_loss: 39875008666.3014\n",
      "Epoch 699/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38776255708.9315 - val_loss: 39874948292.3836\n",
      "Epoch 700/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38776197621.4795 - val_loss: 39874889489.5342\n",
      "Epoch 701/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38776135834.3014 - val_loss: 39874822340.3836\n",
      "Epoch 702/1000\n",
      "1168/1168 [==============================] - 0s 276us/step - loss: 38776070438.5753 - val_loss: 39874762275.0685\n",
      "Epoch 703/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38776011535.7808 - val_loss: 39874700905.2055\n",
      "Epoch 704/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38775951116.2740 - val_loss: 39874640391.0137\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 280us/step - loss: 38775889895.4521 - val_loss: 39874576019.2877\n",
      "Epoch 706/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38775825762.1918 - val_loss: 39874511717.6986\n",
      "Epoch 707/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38775762417.9726 - val_loss: 39874447177.6438\n",
      "Epoch 708/1000\n",
      "1168/1168 [==============================] - 0s 264us/step - loss: 38775699140.3836 - val_loss: 39874383002.3014\n",
      "Epoch 709/1000\n",
      "1168/1168 [==============================] - 0s 258us/step - loss: 38775635817.2055 - val_loss: 39874318616.5479\n",
      "Epoch 710/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38775571171.9452 - val_loss: 39874256910.0274\n",
      "Epoch 711/1000\n",
      "1168/1168 [==============================] - 0s 256us/step - loss: 38775507780.3836 - val_loss: 39874193169.5342\n",
      "Epoch 712/1000\n",
      "1168/1168 [==============================] - 0s 255us/step - loss: 38775447737.8630 - val_loss: 39874132234.5205\n",
      "Epoch 713/1000\n",
      "1168/1168 [==============================] - 0s 255us/step - loss: 38775389285.6986 - val_loss: 39874075255.2329\n",
      "Epoch 714/1000\n",
      "1168/1168 [==============================] - 0s 258us/step - loss: 38775330005.9178 - val_loss: 39874010532.8219\n",
      "Epoch 715/1000\n",
      "1168/1168 [==============================] - 0s 279us/step - loss: 38775267072.0000 - val_loss: 39873950074.7397\n",
      "Epoch 716/1000\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 38775204106.5205 - val_loss: 39873881733.2603\n",
      "Epoch 717/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38775140457.2055 - val_loss: 39873819676.0548\n",
      "Epoch 718/1000\n",
      "1168/1168 [==============================] - 0s 252us/step - loss: 38775076074.9589 - val_loss: 39873752049.9726\n",
      "Epoch 719/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38775010787.9452 - val_loss: 39873688519.8904\n",
      "Epoch 720/1000\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 38774951217.0959 - val_loss: 39873631540.6027\n",
      "Epoch 721/1000\n",
      "1168/1168 [==============================] - 0s 263us/step - loss: 38774890310.1370 - val_loss: 39873567435.3973\n",
      "Epoch 722/1000\n",
      "1168/1168 [==============================] - 0s 246us/step - loss: 38774832329.6438 - val_loss: 39873513696.4384\n",
      "Epoch 723/1000\n",
      "1168/1168 [==============================] - 0s 256us/step - loss: 38774776312.9863 - val_loss: 39873453406.6849\n",
      "Epoch 724/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38774713813.9178 - val_loss: 39873391770.3014\n",
      "Epoch 725/1000\n",
      "1168/1168 [==============================] - 0s 258us/step - loss: 38774654092.2740 - val_loss: 39873335267.9452\n",
      "Epoch 726/1000\n",
      "1168/1168 [==============================] - 0s 277us/step - loss: 38774596078.4658 - val_loss: 39873270755.9452\n",
      "Epoch 727/1000\n",
      "1168/1168 [==============================] - 0s 353us/step - loss: 38774532835.9452 - val_loss: 39873205304.1096\n",
      "Epoch 728/1000\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 38774466275.9452 - val_loss: 39873141002.5205\n",
      "Epoch 729/1000\n",
      "1168/1168 [==============================] - 0s 327us/step - loss: 38774402528.4384 - val_loss: 39873073656.9863\n",
      "Epoch 730/1000\n",
      "1168/1168 [==============================] - 0s 320us/step - loss: 38774340359.0137 - val_loss: 39873016172.7123\n",
      "Epoch 731/1000\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 38774281612.2740 - val_loss: 39872952348.0548\n",
      "Epoch 732/1000\n",
      "1168/1168 [==============================] - 0s 343us/step - loss: 38774220554.5205 - val_loss: 39872895452.9315\n",
      "Epoch 733/1000\n",
      "1168/1168 [==============================] - 0s 332us/step - loss: 38774163094.7945 - val_loss: 39872838249.2055\n",
      "Epoch 734/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38774106746.7397 - val_loss: 39872777735.0137\n",
      "Epoch 735/1000\n",
      "1168/1168 [==============================] - 0s 287us/step - loss: 38774045362.8493 - val_loss: 39872713784.1096\n",
      "Epoch 736/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38773980487.8904 - val_loss: 39872648823.2329\n",
      "Epoch 737/1000\n",
      "1168/1168 [==============================] - 0s 275us/step - loss: 38773915307.8356 - val_loss: 39872583876.3836\n",
      "Epoch 738/1000\n",
      "1168/1168 [==============================] - 0s 279us/step - loss: 38773850392.5479 - val_loss: 39872515184.2192\n",
      "Epoch 739/1000\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 38773785592.9863 - val_loss: 39872454473.6438\n",
      "Epoch 740/1000\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 38773723206.1370 - val_loss: 39872390648.9863\n",
      "Epoch 741/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38773660289.7534 - val_loss: 39872326978.6301\n",
      "Epoch 742/1000\n",
      "1168/1168 [==============================] - 0s 234us/step - loss: 38773597418.9589 - val_loss: 39872261596.9315\n",
      "Epoch 743/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38773533475.0685 - val_loss: 39872197561.8630\n",
      "Epoch 744/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38773472610.1918 - val_loss: 39872139179.8356\n",
      "Epoch 745/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38773410496.8767 - val_loss: 39872072170.9589\n",
      "Epoch 746/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38773343789.5890 - val_loss: 39872004404.6027\n",
      "Epoch 747/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38773281374.6849 - val_loss: 39871946723.9452\n",
      "Epoch 748/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38773221596.9315 - val_loss: 39871885999.3425\n",
      "Epoch 749/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38773159281.9726 - val_loss: 39871821347.0685\n",
      "Epoch 750/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38773097124.8219 - val_loss: 39871759977.2055\n",
      "Epoch 751/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38773036365.1507 - val_loss: 39871696783.7808\n",
      "Epoch 752/1000\n",
      "1168/1168 [==============================] - 0s 285us/step - loss: 38772977379.9452 - val_loss: 39871638485.9178\n",
      "Epoch 753/1000\n",
      "1168/1168 [==============================] - 0s 271us/step - loss: 38772916185.4247 - val_loss: 39871574801.5342\n",
      "Epoch 754/1000\n",
      "1168/1168 [==============================] - 0s 255us/step - loss: 38772850624.8767 - val_loss: 39871509910.7945\n",
      "Epoch 755/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38772786796.7123 - val_loss: 39871445819.6164\n",
      "Epoch 756/1000\n",
      "1168/1168 [==============================] - 0s 251us/step - loss: 38772725118.2466 - val_loss: 39871387577.8630\n",
      "Epoch 757/1000\n",
      "1168/1168 [==============================] - 0s 262us/step - loss: 38772668791.2329 - val_loss: 39871328256.0000\n",
      "Epoch 758/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38772608848.6575 - val_loss: 39871264234.9589\n",
      "Epoch 759/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38772546325.0411 - val_loss: 39871202865.0959\n",
      "Epoch 760/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38772487206.5753 - val_loss: 39871145801.6438\n",
      "Epoch 761/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38772425871.7808 - val_loss: 39871081780.6027\n",
      "Epoch 762/1000\n",
      "1168/1168 [==============================] - 0s 255us/step - loss: 38772361429.9178 - val_loss: 39871014154.5205\n",
      "Epoch 763/1000\n",
      "1168/1168 [==============================] - 0s 274us/step - loss: 38772297510.5753 - val_loss: 39870951606.3562\n",
      "Epoch 764/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38772235702.3562 - val_loss: 39870887515.1781\n",
      "Epoch 765/1000\n",
      "1168/1168 [==============================] - 0s 249us/step - loss: 38772170990.4658 - val_loss: 39870824111.3425\n",
      "Epoch 766/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38772111682.6301 - val_loss: 39870762895.7808\n",
      "Epoch 767/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38772050861.5890 - val_loss: 39870704780.2740\n",
      "Epoch 768/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38771988862.2466 - val_loss: 39870638556.9315\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 237us/step - loss: 38771923627.8356 - val_loss: 39870573764.3836\n",
      "Epoch 770/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38771862848.8767 - val_loss: 39870513460.6027\n",
      "Epoch 771/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38771800777.6438 - val_loss: 39870450491.6164\n",
      "Epoch 772/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38771737496.5479 - val_loss: 39870387157.9178\n",
      "Epoch 773/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38771677380.3836 - val_loss: 39870326152.7671\n",
      "Epoch 774/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38771614502.5753 - val_loss: 39870261977.4247\n",
      "Epoch 775/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38771552752.2192 - val_loss: 39870200832.0000\n",
      "Epoch 776/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38771487933.3699 - val_loss: 39870132294.1370\n",
      "Epoch 777/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38771426083.0685 - val_loss: 39870072579.5069\n",
      "Epoch 778/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38771365709.1507 - val_loss: 39870011504.2192\n",
      "Epoch 779/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38771301228.7123 - val_loss: 39869943653.6986\n",
      "Epoch 780/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38771237707.3973 - val_loss: 39869881512.3288\n",
      "Epoch 781/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38771178657.3151 - val_loss: 39869825318.5753\n",
      "Epoch 782/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38771119514.3014 - val_loss: 39869761564.0548\n",
      "Epoch 783/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38771056406.7945 - val_loss: 39869699576.9863\n",
      "Epoch 784/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38770997074.4110 - val_loss: 39869639792.2192\n",
      "Epoch 785/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38770935390.6849 - val_loss: 39869575322.3014\n",
      "Epoch 786/1000\n",
      "1168/1168 [==============================] - 0s 372us/step - loss: 38770870457.8630 - val_loss: 39869510515.7260\n",
      "Epoch 787/1000\n",
      "1168/1168 [==============================] - 0s 328us/step - loss: 38770807224.1096 - val_loss: 39869446915.5069\n",
      "Epoch 788/1000\n",
      "1168/1168 [==============================] - 0s 330us/step - loss: 38770744144.6575 - val_loss: 39869385068.7123\n",
      "Epoch 789/1000\n",
      "1168/1168 [==============================] - 0s 407us/step - loss: 38770681095.0137 - val_loss: 39869321594.7397\n",
      "Epoch 790/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38770619418.3014 - val_loss: 39869259537.5342\n",
      "Epoch 791/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38770556668.4931 - val_loss: 39869192893.3699\n",
      "Epoch 792/1000\n",
      "1168/1168 [==============================] - 0s 364us/step - loss: 38770491548.0548 - val_loss: 39869127946.5205\n",
      "Epoch 793/1000\n",
      "1168/1168 [==============================] - 0s 269us/step - loss: 38770428047.7808 - val_loss: 39869065187.9452\n",
      "Epoch 794/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38770364233.6438 - val_loss: 39868998389.4795\n",
      "Epoch 795/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38770299781.2603 - val_loss: 39868934648.9863\n",
      "Epoch 796/1000\n",
      "1168/1168 [==============================] - 0s 364us/step - loss: 38770234788.8219 - val_loss: 39868868846.4658\n",
      "Epoch 797/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38770175298.6301 - val_loss: 39868812428.2740\n",
      "Epoch 798/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38770116355.5069 - val_loss: 39868752573.3699\n",
      "Epoch 799/1000\n",
      "1168/1168 [==============================] - 0s 309us/step - loss: 38770057349.2603 - val_loss: 39868691133.3699\n",
      "Epoch 800/1000\n",
      "1168/1168 [==============================] - 0s 337us/step - loss: 38769997431.2329 - val_loss: 39868630408.7671\n",
      "Epoch 801/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38769938179.5069 - val_loss: 39868573078.7945\n",
      "Epoch 802/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38769877416.3288 - val_loss: 39868509394.4110\n",
      "Epoch 803/1000\n",
      "1168/1168 [==============================] - 0s 336us/step - loss: 38769812464.2192 - val_loss: 39868440996.8219\n",
      "Epoch 804/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38769750990.9041 - val_loss: 39868382895.3425\n",
      "Epoch 805/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38769688176.2192 - val_loss: 39868316321.3151\n",
      "Epoch 806/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38769624270.9041 - val_loss: 39868251879.4521\n",
      "Epoch 807/1000\n",
      "1168/1168 [==============================] - 0s 263us/step - loss: 38769556855.2329 - val_loss: 39868183888.6575\n",
      "Epoch 808/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38769489513.2055 - val_loss: 39868115547.1781\n",
      "Epoch 809/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38769424664.5479 - val_loss: 39868049604.3836\n",
      "Epoch 810/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38769360050.8493 - val_loss: 39867985583.3425\n",
      "Epoch 811/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38769295065.4247 - val_loss: 39867920650.5205\n",
      "Epoch 812/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38769230995.2877 - val_loss: 39867855184.6575\n",
      "Epoch 813/1000\n",
      "1168/1168 [==============================] - 0s 242us/step - loss: 38769167149.5890 - val_loss: 39867791921.0959\n",
      "Epoch 814/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38769102272.8767 - val_loss: 39867724856.1096\n",
      "Epoch 815/1000\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 38769039826.4110 - val_loss: 39867667175.4521\n",
      "Epoch 816/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38768976597.9178 - val_loss: 39867598202.7397\n",
      "Epoch 817/1000\n",
      "1168/1168 [==============================] - 0s 313us/step - loss: 38768914756.3836 - val_loss: 39867537702.5753\n",
      "Epoch 818/1000\n",
      "1168/1168 [==============================] - 0s 307us/step - loss: 38768855211.8356 - val_loss: 39867477482.9589\n",
      "Epoch 819/1000\n",
      "1168/1168 [==============================] - 0s 304us/step - loss: 38768793489.5342 - val_loss: 39867416618.0822\n",
      "Epoch 820/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38768728917.9178 - val_loss: 39867349118.2466\n",
      "Epoch 821/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38768669355.8356 - val_loss: 39867290525.8082\n",
      "Epoch 822/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38768607617.7534 - val_loss: 39867226995.7260\n",
      "Epoch 823/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38768543480.9863 - val_loss: 39867162946.6301\n",
      "Epoch 824/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38768483562.9589 - val_loss: 39867104564.6027\n",
      "Epoch 825/1000\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 38768422129.9726 - val_loss: 39867039968.4384\n",
      "Epoch 826/1000\n",
      "1168/1168 [==============================] - 0s 257us/step - loss: 38768359864.1096 - val_loss: 39866979720.7671\n",
      "Epoch 827/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38768299512.9863 - val_loss: 39866916415.1233\n",
      "Epoch 828/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38768239352.9863 - val_loss: 39866858580.1644\n",
      "Epoch 829/1000\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 38768177032.7671 - val_loss: 39866794699.3973\n",
      "Epoch 830/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38768113344.8767 - val_loss: 39866729808.6575\n",
      "Epoch 831/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38768048534.7945 - val_loss: 39866661326.9041\n",
      "Epoch 832/1000\n",
      "1168/1168 [==============================] - 0s 262us/step - loss: 38767985239.6712 - val_loss: 39866598568.3288\n",
      "Epoch 833/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 328us/step - loss: 38767920629.4795 - val_loss: 39866533551.3425\n",
      "Epoch 834/1000\n",
      "1168/1168 [==============================] - 0s 323us/step - loss: 38767856829.3699 - val_loss: 39866467468.2740\n",
      "Epoch 835/1000\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 38767792327.8904 - val_loss: 39866404078.4658\n",
      "Epoch 836/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38767731855.7808 - val_loss: 39866346467.9452\n",
      "Epoch 837/1000\n",
      "1168/1168 [==============================] - 0s 262us/step - loss: 38767674224.2192 - val_loss: 39866289067.8356\n",
      "Epoch 838/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38767611662.0274 - val_loss: 39866221006.9041\n",
      "Epoch 839/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38767545699.9452 - val_loss: 39866153927.8904\n",
      "Epoch 840/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38767481591.2329 - val_loss: 39866089345.7534\n",
      "Epoch 841/1000\n",
      "1168/1168 [==============================] - 0s 254us/step - loss: 38767416554.9589 - val_loss: 39866027779.5069\n",
      "Epoch 842/1000\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 38767353445.6986 - val_loss: 39865959452.0548\n",
      "Epoch 843/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38767287590.5753 - val_loss: 39865894869.9178\n",
      "Epoch 844/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38767223685.2603 - val_loss: 39865833920.8767\n",
      "Epoch 845/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38767163002.7397 - val_loss: 39865771372.7123\n",
      "Epoch 846/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38767102001.0959 - val_loss: 39865708810.5205\n",
      "Epoch 847/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38767037510.1370 - val_loss: 39865640483.0685\n",
      "Epoch 848/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38766972994.6301 - val_loss: 39865576742.5753\n",
      "Epoch 849/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38766908928.0000 - val_loss: 39865514755.5069\n",
      "Epoch 850/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38766845992.3288 - val_loss: 39865447199.5616\n",
      "Epoch 851/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38766777915.6164 - val_loss: 39865379208.7671\n",
      "Epoch 852/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38766714073.4247 - val_loss: 39865315384.1096\n",
      "Epoch 853/1000\n",
      "1168/1168 [==============================] - 0s 293us/step - loss: 38766649985.7534 - val_loss: 39865253537.3151\n",
      "Epoch 854/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38766587437.5890 - val_loss: 39865190077.3699\n",
      "Epoch 855/1000\n",
      "1168/1168 [==============================] - 0s 224us/step - loss: 38766525159.4521 - val_loss: 39865128160.4384\n",
      "Epoch 856/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38766462804.1644 - val_loss: 39865061852.9315\n",
      "Epoch 857/1000\n",
      "1168/1168 [==============================] - 0s 235us/step - loss: 38766400424.3288 - val_loss: 39864999220.6027\n",
      "Epoch 858/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38766337325.5890 - val_loss: 39864936181.4795\n",
      "Epoch 859/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38766273006.4658 - val_loss: 39864871248.6575\n",
      "Epoch 860/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38766211015.8904 - val_loss: 39864810103.2329\n",
      "Epoch 861/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38766147580.4931 - val_loss: 39864745521.0959\n",
      "Epoch 862/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38766088984.5479 - val_loss: 39864689523.7260\n",
      "Epoch 863/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38766033604.3836 - val_loss: 39864632263.8904\n",
      "Epoch 864/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38765973374.2466 - val_loss: 39864570823.8904\n",
      "Epoch 865/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38765910570.0822 - val_loss: 39864507153.5342\n",
      "Epoch 866/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38765850645.0411 - val_loss: 39864445994.0822\n",
      "Epoch 867/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38765789846.7945 - val_loss: 39864385479.8904\n",
      "Epoch 868/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38765728466.4110 - val_loss: 39864327869.3699\n",
      "Epoch 869/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38765675751.4521 - val_loss: 39864275687.4521\n",
      "Epoch 870/1000\n",
      "1168/1168 [==============================] - 0s 227us/step - loss: 38765620020.6027 - val_loss: 39864218076.9315\n",
      "Epoch 871/1000\n",
      "1168/1168 [==============================] - 0s 226us/step - loss: 38765561161.6438 - val_loss: 39864154616.9863\n",
      "Epoch 872/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38765496989.8082 - val_loss: 39864087201.3151\n",
      "Epoch 873/1000\n",
      "1168/1168 [==============================] - 0s 233us/step - loss: 38765434059.3973 - val_loss: 39864028959.5616\n",
      "Epoch 874/1000\n",
      "1168/1168 [==============================] - 0s 225us/step - loss: 38765375719.4521 - val_loss: 39863967659.8356\n",
      "Epoch 875/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38765313029.2603 - val_loss: 39863906851.0685\n",
      "Epoch 876/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38765255048.7671 - val_loss: 39863846659.5069\n",
      "Epoch 877/1000\n",
      "1168/1168 [==============================] - 0s 232us/step - loss: 38765193563.1781 - val_loss: 39863782105.4247\n",
      "Epoch 878/1000\n",
      "1168/1168 [==============================] - 0s 228us/step - loss: 38765131679.5616 - val_loss: 39863718505.2055\n",
      "Epoch 879/1000\n",
      "1168/1168 [==============================] - 0s 277us/step - loss: 38765070015.1233 - val_loss: 39863657079.2329\n",
      "Epoch 880/1000\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 38765008818.8493 - val_loss: 39863596733.3699\n",
      "Epoch 881/1000\n",
      "1168/1168 [==============================] - 0s 276us/step - loss: 38764949358.4658 - val_loss: 39863536499.7260\n",
      "Epoch 882/1000\n",
      "1168/1168 [==============================] - 0s 276us/step - loss: 38764889042.4110 - val_loss: 39863473797.2603\n",
      "Epoch 883/1000\n",
      "1168/1168 [==============================] - 0s 275us/step - loss: 38764823923.7260 - val_loss: 39863409425.5342\n",
      "Epoch 884/1000\n",
      "1168/1168 [==============================] - 0s 278us/step - loss: 38764758282.5205 - val_loss: 39863342276.3836\n",
      "Epoch 885/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38764698189.1507 - val_loss: 39863284665.8630\n",
      "Epoch 886/1000\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 38764634683.6164 - val_loss: 39863216969.6438\n",
      "Epoch 887/1000\n",
      "1168/1168 [==============================] - 0s 328us/step - loss: 38764569796.3836 - val_loss: 39863149539.9452\n",
      "Epoch 888/1000\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 38764505028.3836 - val_loss: 39863085098.0822\n",
      "Epoch 889/1000\n",
      "1168/1168 [==============================] - 0s 299us/step - loss: 38764437542.5753 - val_loss: 39863019211.3973\n",
      "Epoch 890/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38764374272.0000 - val_loss: 39862958725.2603\n",
      "Epoch 891/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38764317901.1507 - val_loss: 39862899052.7123\n",
      "Epoch 892/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38764258114.6301 - val_loss: 39862840670.6849\n",
      "Epoch 893/1000\n",
      "1168/1168 [==============================] - 0s 230us/step - loss: 38764197158.5753 - val_loss: 39862777280.8767\n",
      "Epoch 894/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38764131976.7671 - val_loss: 39862708953.4247\n",
      "Epoch 895/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38764065486.9041 - val_loss: 39862643557.6986\n",
      "Epoch 896/1000\n",
      "1168/1168 [==============================] - 0s 231us/step - loss: 38763999617.7534 - val_loss: 39862575426.6301\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 251us/step - loss: 38763935363.5069 - val_loss: 39862512668.0548\n",
      "Epoch 898/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38763874447.7808 - val_loss: 39862454356.1644\n",
      "Epoch 899/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38763812993.7534 - val_loss: 39862386028.7123\n",
      "Epoch 900/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38763747871.5616 - val_loss: 39862322414.4658\n",
      "Epoch 901/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38763683825.9726 - val_loss: 39862260834.1918\n",
      "Epoch 902/1000\n",
      "1168/1168 [==============================] - 0s 238us/step - loss: 38763621207.6712 - val_loss: 39862193769.2055\n",
      "Epoch 903/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38763557149.8082 - val_loss: 39862131641.8630\n",
      "Epoch 904/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38763495974.5753 - val_loss: 39862071085.5890\n",
      "Epoch 905/1000\n",
      "1168/1168 [==============================] - 0s 244us/step - loss: 38763434955.3973 - val_loss: 39862009238.7945\n",
      "Epoch 906/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38763376005.2603 - val_loss: 39861950267.6164\n",
      "Epoch 907/1000\n",
      "1168/1168 [==============================] - 0s 236us/step - loss: 38763314200.5479 - val_loss: 39861885180.4931\n",
      "Epoch 908/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38763253233.9726 - val_loss: 39861821860.8219\n",
      "Epoch 909/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38763187547.1781 - val_loss: 39861759102.2466\n",
      "Epoch 910/1000\n",
      "1168/1168 [==============================] - 0s 239us/step - loss: 38763126296.5479 - val_loss: 39861696610.1918\n",
      "Epoch 911/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38763064593.5342 - val_loss: 39861634202.3014\n",
      "Epoch 912/1000\n",
      "1168/1168 [==============================] - 0s 248us/step - loss: 38763001992.7671 - val_loss: 39861570461.8082\n",
      "Epoch 913/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38762939967.1233 - val_loss: 39861509035.8356\n",
      "Epoch 914/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38762877916.9315 - val_loss: 39861445646.0274\n",
      "Epoch 915/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38762815838.6849 - val_loss: 39861385117.8082\n",
      "Epoch 916/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38762753234.4110 - val_loss: 39861316986.7397\n",
      "Epoch 917/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38762691436.7123 - val_loss: 39861259376.2192\n",
      "Epoch 918/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38762634766.0274 - val_loss: 39861202046.2466\n",
      "Epoch 919/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38762576976.6575 - val_loss: 39861145557.9178\n",
      "Epoch 920/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38762515789.1507 - val_loss: 39861078072.1096\n",
      "Epoch 921/1000\n",
      "1168/1168 [==============================] - 0s 241us/step - loss: 38762454654.2466 - val_loss: 39861020251.1781\n",
      "Epoch 922/1000\n",
      "1168/1168 [==============================] - 0s 246us/step - loss: 38762395774.2466 - val_loss: 39860962851.0685\n",
      "Epoch 923/1000\n",
      "1168/1168 [==============================] - 0s 245us/step - loss: 38762335624.7671 - val_loss: 39860895701.9178\n",
      "Epoch 924/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38762271530.0822 - val_loss: 39860834416.2192\n",
      "Epoch 925/1000\n",
      "1168/1168 [==============================] - 0s 243us/step - loss: 38762207768.5479 - val_loss: 39860769258.9589\n",
      "Epoch 926/1000\n",
      "1168/1168 [==============================] - 0s 264us/step - loss: 38762142095.7808 - val_loss: 39860701212.0548\n",
      "Epoch 927/1000\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 38762078600.7671 - val_loss: 39860638172.9315\n",
      "Epoch 928/1000\n",
      "1168/1168 [==============================] - 0s 265us/step - loss: 38762014236.0548 - val_loss: 39860572370.4110\n",
      "Epoch 929/1000\n",
      "1168/1168 [==============================] - 0s 259us/step - loss: 38761949573.2603 - val_loss: 39860509176.9863\n",
      "Epoch 930/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38761889029.2603 - val_loss: 39860450808.9863\n",
      "Epoch 931/1000\n",
      "1168/1168 [==============================] - 0s 256us/step - loss: 38761831844.8219 - val_loss: 39860394096.2192\n",
      "Epoch 932/1000\n",
      "1168/1168 [==============================] - 0s 268us/step - loss: 38761773052.4931 - val_loss: 39860330341.6986\n",
      "Epoch 933/1000\n",
      "1168/1168 [==============================] - 0s 328us/step - loss: 38761714226.8493 - val_loss: 39860273081.8630\n",
      "Epoch 934/1000\n",
      "1168/1168 [==============================] - 0s 297us/step - loss: 38761652557.1507 - val_loss: 39860207770.3014\n",
      "Epoch 935/1000\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 38761588122.3014 - val_loss: 39860144029.8082\n",
      "Epoch 936/1000\n",
      "1168/1168 [==============================] - 0s 279us/step - loss: 38761526899.7260 - val_loss: 39860083305.2055\n",
      "Epoch 937/1000\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 38761464246.3562 - val_loss: 39860018302.2466\n",
      "Epoch 938/1000\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 38761402031.3425 - val_loss: 39859957423.3425\n",
      "Epoch 939/1000\n",
      "1168/1168 [==============================] - 0s 304us/step - loss: 38761340580.8219 - val_loss: 39859893949.3699\n",
      "Epoch 940/1000\n",
      "1168/1168 [==============================] - 0s 269us/step - loss: 38761282679.2329 - val_loss: 39859836633.4247\n",
      "Epoch 941/1000\n",
      "1168/1168 [==============================] - 0s 250us/step - loss: 38761221270.7945 - val_loss: 39859772878.9041\n",
      "Epoch 942/1000\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 38761154291.7260 - val_loss: 39859704481.3151\n",
      "Epoch 943/1000\n",
      "1168/1168 [==============================] - 0s 266us/step - loss: 38761091405.1507 - val_loss: 39859644107.3973\n",
      "Epoch 944/1000\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 38761029183.1233 - val_loss: 39859578683.6164\n",
      "Epoch 945/1000\n",
      "1168/1168 [==============================] - 0s 278us/step - loss: 38760965828.3836 - val_loss: 39859517664.4384\n",
      "Epoch 946/1000\n",
      "1168/1168 [==============================] - 0s 263us/step - loss: 38760904465.5342 - val_loss: 39859454681.4247\n",
      "Epoch 947/1000\n",
      "1168/1168 [==============================] - 0s 260us/step - loss: 38760844445.8082 - val_loss: 39859397295.3425\n",
      "Epoch 948/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38760785765.6986 - val_loss: 39859335995.6164\n",
      "Epoch 949/1000\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 38760725486.4658 - val_loss: 39859274780.0548\n",
      "Epoch 950/1000\n",
      "1168/1168 [==============================] - 0s 269us/step - loss: 38760663211.8356 - val_loss: 39859210408.3288\n",
      "Epoch 951/1000\n",
      "1168/1168 [==============================] - 0s 271us/step - loss: 38760598045.8082 - val_loss: 39859143048.7671\n",
      "Epoch 952/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38760535604.6027 - val_loss: 39859081833.2055\n",
      "Epoch 953/1000\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 38760473708.7123 - val_loss: 39859022118.5753\n",
      "Epoch 954/1000\n",
      "1168/1168 [==============================] - 0s 275us/step - loss: 38760415337.2055 - val_loss: 39858961450.0822\n",
      "Epoch 955/1000\n",
      "1168/1168 [==============================] - 0s 310us/step - loss: 38760354367.1233 - val_loss: 39858899673.4247\n",
      "Epoch 956/1000\n",
      "1168/1168 [==============================] - 0s 330us/step - loss: 38760292972.7123 - val_loss: 39858836143.3425\n",
      "Epoch 957/1000\n",
      "1168/1168 [==============================] - 0s 340us/step - loss: 38760233706.9589 - val_loss: 39858779374.4658\n",
      "Epoch 958/1000\n",
      "1168/1168 [==============================] - 0s 393us/step - loss: 38760176881.9726 - val_loss: 39858721413.2603\n",
      "Epoch 959/1000\n",
      "1168/1168 [==============================] - 0s 363us/step - loss: 38760115333.2603 - val_loss: 39858657462.3562\n",
      "Epoch 960/1000\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 38760054587.6164 - val_loss: 39858596246.7945\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 260us/step - loss: 38759993880.5479 - val_loss: 39858535732.6027\n",
      "Epoch 962/1000\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 38759930150.5753 - val_loss: 39858471136.4384\n",
      "Epoch 963/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38759868600.1096 - val_loss: 39858407452.0548\n",
      "Epoch 964/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38759804268.7123 - val_loss: 39858345675.3973\n",
      "Epoch 965/1000\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 38759744028.0548 - val_loss: 39858288135.0137\n",
      "Epoch 966/1000\n",
      "1168/1168 [==============================] - 0s 263us/step - loss: 38759687038.2466 - val_loss: 39858227550.6849\n",
      "Epoch 967/1000\n",
      "1168/1168 [==============================] - 0s 237us/step - loss: 38759627870.6849 - val_loss: 39858168116.6027\n",
      "Epoch 968/1000\n",
      "1168/1168 [==============================] - 0s 229us/step - loss: 38759567812.3836 - val_loss: 39858107041.3151\n",
      "Epoch 969/1000\n",
      "1168/1168 [==============================] - 0s 251us/step - loss: 38759507133.3699 - val_loss: 39858043441.0959\n",
      "Epoch 970/1000\n",
      "1168/1168 [==============================] - 0s 275us/step - loss: 38759443568.2192 - val_loss: 39857981510.1370\n",
      "Epoch 971/1000\n",
      "1168/1168 [==============================] - 0s 317us/step - loss: 38759380052.1644 - val_loss: 39857913519.3425\n",
      "Epoch 972/1000\n",
      "1168/1168 [==============================] - 0s 369us/step - loss: 38759317123.5069 - val_loss: 39857853355.8356\n",
      "Epoch 973/1000\n",
      "1168/1168 [==============================] - 0s 370us/step - loss: 38759254324.6027 - val_loss: 39857788352.8767\n",
      "Epoch 974/1000\n",
      "1168/1168 [==============================] - 0s 400us/step - loss: 38759193578.9589 - val_loss: 39857730602.0822\n",
      "Epoch 975/1000\n",
      "1168/1168 [==============================] - 0s 401us/step - loss: 38759134902.3562 - val_loss: 39857667913.6438\n",
      "Epoch 976/1000\n",
      "1168/1168 [==============================] - 0s 311us/step - loss: 38759072329.6438 - val_loss: 39857606193.0959\n",
      "Epoch 977/1000\n",
      "1168/1168 [==============================] - 0s 258us/step - loss: 38759008906.5205 - val_loss: 39857539464.7671\n",
      "Epoch 978/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38758943537.0959 - val_loss: 39857473914.7397\n",
      "Epoch 979/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38758878523.6164 - val_loss: 39857411703.2329\n",
      "Epoch 980/1000\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 38758818181.2603 - val_loss: 39857348243.2877\n",
      "Epoch 981/1000\n",
      "1168/1168 [==============================] - 0s 314us/step - loss: 38758754686.2466 - val_loss: 39857286817.3151\n",
      "Epoch 982/1000\n",
      "1168/1168 [==============================] - 0s 357us/step - loss: 38758692920.1096 - val_loss: 39857219261.3699\n",
      "Epoch 983/1000\n",
      "1168/1168 [==============================] - 0s 272us/step - loss: 38758630170.3014 - val_loss: 39857162478.4658\n",
      "Epoch 984/1000\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 38758568774.1370 - val_loss: 39857095259.1781\n",
      "Epoch 985/1000\n",
      "1168/1168 [==============================] - 0s 329us/step - loss: 38758504383.1233 - val_loss: 39857033131.8356\n",
      "Epoch 986/1000\n",
      "1168/1168 [==============================] - 0s 312us/step - loss: 38758442846.6849 - val_loss: 39856968900.3836\n",
      "Epoch 987/1000\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 38758382371.0685 - val_loss: 39856908245.9178\n",
      "Epoch 988/1000\n",
      "1168/1168 [==============================] - 0s 270us/step - loss: 38758320362.9589 - val_loss: 39856848110.4658\n",
      "Epoch 989/1000\n",
      "1168/1168 [==============================] - 0s 303us/step - loss: 38758258742.3562 - val_loss: 39856787175.4521\n",
      "Epoch 990/1000\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 38758196273.0959 - val_loss: 39856719198.6849\n",
      "Epoch 991/1000\n",
      "1168/1168 [==============================] - 0s 276us/step - loss: 38758134226.4110 - val_loss: 39856656987.1781\n",
      "Epoch 992/1000\n",
      "1168/1168 [==============================] - 0s 332us/step - loss: 38758069619.7260 - val_loss: 39856593162.5205\n",
      "Epoch 993/1000\n",
      "1168/1168 [==============================] - 0s 261us/step - loss: 38758005917.8082 - val_loss: 39856529772.7123\n",
      "Epoch 994/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38757945989.2603 - val_loss: 39856467785.6438\n",
      "Epoch 995/1000\n",
      "1168/1168 [==============================] - 0s 247us/step - loss: 38757884594.8493 - val_loss: 39856407201.3151\n",
      "Epoch 996/1000\n",
      "1168/1168 [==============================] - 0s 253us/step - loss: 38757819963.6164 - val_loss: 39856342969.8630\n",
      "Epoch 997/1000\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 38757756735.1233 - val_loss: 39856275680.4384\n",
      "Epoch 998/1000\n",
      "1168/1168 [==============================] - 0s 240us/step - loss: 38757693822.2466 - val_loss: 39856213482.9589\n",
      "Epoch 999/1000\n",
      "1168/1168 [==============================] - 0s 340us/step - loss: 38757629759.1233 - val_loss: 39856149868.7123\n",
      "Epoch 1000/1000\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 38757569315.0685 - val_loss: 39856089284.3836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17c90833488>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train.values,y_train.values,\n",
    "              validation_split=0.2,batch_size=10,\n",
    "              epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[171.47908],\n",
       "       [171.47908],\n",
       "       [171.47908],\n",
       "       ...,\n",
       "       [171.47908],\n",
       "       [171.47908],\n",
       "       [171.47908]], dtype=float32)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
